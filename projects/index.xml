<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Trefoil analytics</title>
    <link>/projects/index.xml</link>
    <description>Recent content in Projects on Trefoil analytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;2017 Trefoil analytics</copyright>
    <lastBuildDate>Thu, 02 Mar 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/projects/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Loan default and customer churn prediction</title>
      <link>/projects/loan_and_churn/</link>
      <pubDate>Thu, 02 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/projects/loan_and_churn/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;!-- BLOGDOWN-BODY-BEFORE --&gt;
&lt;!-- /BLOGDOWN-BODY-BEFORE --&gt;
&lt;div id=&#34;the-challenge&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The challenge&lt;/h4&gt;
&lt;p&gt;A lending company decided to to modernize their risk management system by setting up an early warning system on default, bad debt and churn to improve their risk management process.The company decided to set up an internal secure server populated by a large SQL database, an analytic engine and a visualization layer/dashboard. The objectives of this application are summarized as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Build and evaluate a model for credit risk and credit scoring for personal loan.&lt;/li&gt;
&lt;li&gt;Build and evaluate a model for customer churn prediction.&lt;/li&gt;
&lt;li&gt;Deploy the models in a production environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;../DCR/credit_churn.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trefoil analytics helped by preparing the data and building predictive models for defaults risk and churn rate, see this blog, and to define the content of the user interface.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;examples-of-technologies-used-include-the-following&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Examples of technologies used include the following&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;SQL, R, Python and Azure ML&lt;/li&gt;
&lt;li&gt;Logistic regression, survival analysis, (survival) random forests.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Features building and evaluation, model performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Gender Equality and Dialogue in 2016’s Highest Grossing Films</title>
      <link>/projects/MovieDialogue/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/projects/MovieDialogue/</guid>
      <description>&lt;link href=&#34;/rmarkdown-libs/font-awesome/css/font-awesome.min.css&#34; rel=&#34;stylesheet&#34; /&gt;

&lt;p&gt;Jump straight to the &lt;a href=&#34;https://ProQuestionAsker.github.io/projects/MovieDialogueInteractive/&#34;&gt;Interactive Graphic&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#choosing-the-movies&#34;&gt;Choosing the Movies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deciding-on-data-collection&#34;&gt;Deciding on Data Collection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#analysis&#34;&gt;Analysis&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#assigning-gender-to-characters&#34;&gt;Assigning Gender to Characters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#counting-words&#34;&gt;Counting Words&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualizing-the-data&#34;&gt;Visualizing the Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#in-r&#34;&gt;In R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#in-illustrator&#34;&gt;In Illustrator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#adding-interactivity-with-d3.js&#34;&gt;Adding Interactivity with d3.js&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#color-considerations&#34;&gt;Color Considerations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#key-takeaways&#34;&gt;Key Takeaways&lt;/a&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#future-work&#34;&gt;Future Work&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Unlike most of my personal projects, this one didn’t start with a dataset. It started with going to see the newest movie from the Star Wars universe: Rogue One.&lt;/p&gt;
&lt;p&gt;While I’m not a die-hard member of the Star Wars fandom, I did grow up watching the films (my father IS a devoted member of the fandom) and truly enjoying the stories. Like many other little girls watching those movies, Princess Leia’s character always resonated with me because she was &lt;a href=&#34;https://www.youtube.com/watch?v=ODgwL7DJ9dY&#34;&gt;just about the only speaking female character&lt;/a&gt; in the original trilogy.&lt;/p&gt;
&lt;p&gt;But things have changed since the late 1970’s and early 1980’s when those movies were released. I mean, Disney/Lucas Films has released 2 movies in the past 2 years and BOTH have female leads! Things have got to be better than they were, right? Well, I definitely had high hopes for female equality in the Star Wars Universe until I actually watched Rogue One. Jyn Erso was indeed a main character, but like Princess Leia she seemed to be totally surrounded by men in nearly every scene. And while the film does &lt;em&gt;technically&lt;/em&gt; pass &lt;a href=&#34;http://bechdeltest.com/&#34;&gt;The Bechdel Test&lt;/a&gt; (brief conversations between Jyn and both her mother and Mon Mothma allowed this box to be checked off), it felt far from equal. Being data-minded, I wanted to &lt;em&gt;see&lt;/em&gt; how many female characters there actually were, and how much they spoke throught the story.&lt;/p&gt;
&lt;div id=&#34;choosing-the-movies&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Choosing the Movies&lt;/h3&gt;
&lt;p&gt;Originally, I planned to look at the transcripts of all the Star Wars movies to see if female representation really has changed over the years, but again, several of those movies were created almost 40 years ago. Is it fair to compare them directly? So, I started thinking about comparing movies that were all created at the same time. That is, movies that were all released in 2016. To limit this project to some sort of semi-reasonable scope, I decided to keep it to the Top 10 &lt;a href=&#34;http://www.the-numbers.com/movie/records/worldwide/2016&#34;&gt;Highest Grossing Movies Worldwide&lt;/a&gt; from 2016. That left me with the following movies in this order:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt3498820/?ref_=nv_sr_1&#34;&gt;Captain America: Civil War&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt2277860/?ref_=nv_sr_1&#34;&gt;Finding Dory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt2948356/?ref_=nv_sr_1&#34;&gt;Zootopia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt3040964/?ref_=nv_sr_1&#34;&gt;The Jungle Book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt2709768/?ref_=nv_sr_1&#34;&gt;The Secret Life of Pets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt2975590/?ref_=nv_sr_1&#34;&gt;Batman V. Superman: Dawn of Justice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt3748528/?ref_=nv_sr_2&#34;&gt;Rogue One: A Star Wars Story&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt1431045/?ref_=nv_sr_1&#34;&gt;Deadpool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt3183660/?ref_=nv_sr_1&#34;&gt;Fantastic Beasts and Where to Find Them&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.imdb.com/title/tt1386697/?ref_=nv_sr_1&#34;&gt;Suicide Squad&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That’s 4 superhero/action movies, 2 Sci-Fi/Fantasy, and 4 animated or family movies. Not a perfect distribution of movie genres, but at least there’s a bit of variety.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;deciding-on-data-collection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Deciding on Data Collection&lt;/h3&gt;
&lt;p&gt;I decided to delve a little bit into similar data exploration projects that have been conducted (like &lt;a href=&#34;http://polygraph.cool/films/&#34;&gt;this one&lt;/a&gt; or &lt;a href=&#34;https://seejane.org/research-informs-empowers/data/&#34;&gt;this one&lt;/a&gt;) and found that I could look at a few things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On-Screen Time&lt;/li&gt;
&lt;li&gt;Words Spoken per Character&lt;/li&gt;
&lt;li&gt;Number of Female Characters&lt;/li&gt;
&lt;li&gt;Number of Female “Lead” Characters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While some &lt;a href=&#34;http://www.cinemetrics.lv/cinemetrics.php&#34;&gt;really cool technology&lt;/a&gt; exists to help measure screen time in movies, it seemed to either be something that I couldn’t use for a side project fueled by my own curiosity or had to be done manually and would thus have taken forever.&lt;/p&gt;
&lt;p&gt;Instead, I decided to focus on dialogue. I considered using screenplays as my source for movie dialogue, but so many of them were not publicly available. However, dedicated movie fans tend to transcribe movie dialogue and post the transcripts on the internet. Tracking those down took some work, but once I found them, it was relatively smooth sailing. For a few, I couldn’t find a transcript, but I was able to find closed caption files. For those, I had to re-watch the movie and manually add in which character said each line.&lt;/p&gt;
&lt;p&gt;I did mention that I was &lt;em&gt;really&lt;/em&gt; curious about this issue, right?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis&lt;/h2&gt;
&lt;p&gt;Once I had all of the transcripts either from fans or captions, it was just a matter of reading the .txt file into R and counting the words per character. I’ll show various stages of the Rogue One graphics throughout this post, but the analysis was the same for each movie. The process looked like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Installing Necessary Packages

# For Web Scraping Transcripts
library(rvest)
library(curl)

# For Data Frame Manipulation
library(dplyr)
library(tidyr)
library(stringr)
library(stringi)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Import Transcript (with formatting)
RO &amp;lt;- readLines(&amp;quot;RogueOneTranscript.txt&amp;quot;)

# Convert to Data Frame
RO &amp;lt;- as.data.frame(RO)

# Remove empty rows
RO &amp;lt;- RO %&amp;gt;% 
        filter(!(RO == &amp;quot;&amp;quot;))

# Separating Character from words
RO_full &amp;lt;- RO %&amp;gt;% 
          separate(col = RO, into = c(&amp;quot;Character&amp;quot;, &amp;quot;Words&amp;quot;), sep = &amp;quot;:&amp;quot;, extra = &amp;quot;merge&amp;quot;) %&amp;gt;% 
          # Eliminate script notes
          filter(!is.na(Words)) %&amp;gt;% 
          # Trim white space and convert Character to factor
          mutate(Character = as.factor(str_trim(Character)), 
                 Words = str_trim(Words))
&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;assigning-gender-to-characters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Assigning Gender to Characters&lt;/h3&gt;
&lt;p&gt;Now that I had a data frame with both Character and Words columns, I had to assign Genders to each Character. This was sometimes quite challenging. Here’s how I did it:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;When possible, use the pronoun that other characters use. If a character is referred to by others as “he” or “him”, then it’s a male character.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If there is no pronoun used throughout the movie but the character is named or credited, use the gender of the actor/actress (using IMDB).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;i class=&#34;fa fa-arrow-circle-right&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt; &lt;strong&gt;Disclaimer: Gender of actors/actresses assumed based on publicly available information as of January 2017.&lt;/strong&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;If there is no pronoun used for a character and the character is not named or credited, look at the closed captions. Sometimes they will name the character that spoke.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If all else fails, make an educated guess based on the character’s voice.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I’ll be the first to say that these methods are not perfect. But for a personal project where I just want to explore some data, I feel like it’s pretty good. However, if you caught a mistake on my part, please &lt;a href=&#34;https://proquestionasker.github.io/contact/&#34;&gt;let me know&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In R, I assigned genders to characters like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assign Genders to Rogue One Characters

RO_males &amp;lt;- c(&amp;quot;Admiral Raddus&amp;quot;, &amp;quot;Announcer&amp;quot;, &amp;quot;Bail Organa&amp;quot;, &amp;quot;Baze Malbus&amp;quot;, &amp;quot;Blue Squadron 1&amp;quot;, &amp;quot;Blue Squadron 2&amp;quot;, &amp;quot;Blue Squadron 3&amp;quot;, &amp;quot;Blue Squadron 4&amp;quot;, &amp;quot;Bodhi Rook&amp;quot;, &amp;quot;C3PO&amp;quot;, &amp;quot;Captain Antilles&amp;quot;, &amp;quot;Cassian&amp;quot;, &amp;quot;Chirrut Imwe&amp;quot;, &amp;quot;Corvette 5&amp;quot;, &amp;quot;Edrio&amp;quot;, &amp;quot;Imperial Soldiers&amp;quot;, &amp;quot;Engineers&amp;quot;, &amp;quot;Flight Control&amp;quot;, &amp;quot;Galen&amp;quot;, &amp;quot;Gate Control&amp;quot;, &amp;quot;General Dodonna&amp;quot;, &amp;quot;General Draven&amp;quot;, &amp;quot;General Merrick&amp;quot;, &amp;quot;General Ramda&amp;quot;, &amp;quot;Gold Leader&amp;quot;, &amp;quot;Governor Tarkin&amp;quot;, &amp;quot;Imperial Assistant&amp;quot;, &amp;quot;Imperial Assistant 2&amp;quot;, &amp;quot;Imperial Assistant 3&amp;quot;, &amp;quot;Imperial Controller&amp;quot;, &amp;quot;Imperial Mission Control&amp;quot;, &amp;quot;Imperial Mission Control 2&amp;quot;, &amp;quot;Imperial Officer&amp;quot;, &amp;quot;Imperial Officer 2&amp;quot;, &amp;quot;Imperial Officer 3&amp;quot;, &amp;quot;Imperial Pilot&amp;quot;, &amp;quot;Imperial Pilot 2&amp;quot;, &amp;quot;Inspector&amp;quot;, &amp;quot;K2SO&amp;quot;, &amp;quot;Krennic&amp;quot;, &amp;quot;Lieutenant Sefla&amp;quot;, &amp;quot;Dr. Cornelius Evazan&amp;quot;, &amp;quot;Pad 12&amp;quot;, &amp;quot;Prisoner&amp;quot;, &amp;quot;Rebel Announcer&amp;quot;, &amp;quot;Rebel Army&amp;quot;, &amp;quot;Rebel Fighter&amp;quot;, &amp;quot;Rebel Officer&amp;quot;, &amp;quot;Rebel Officer 2&amp;quot;, &amp;quot;Rebel Pilot&amp;quot;, &amp;quot;Rebel Pilot 2&amp;quot;, &amp;quot;Rebel Pilot 3&amp;quot;, &amp;quot;Rebel Pilot 4&amp;quot;, &amp;quot;Rebel Pilot 5&amp;quot;, &amp;quot;Rebel Soldier&amp;quot;, &amp;quot;Rebel Soldier 1&amp;quot;, &amp;quot;Rebel Soldier 10&amp;quot;, &amp;quot;Rebel Soldier 2&amp;quot;, &amp;quot;Rebel Soldier 3&amp;quot;, &amp;quot;Rebel Soldier 4&amp;quot;, &amp;quot;Rebel Soldier 5&amp;quot;, &amp;quot;Rebel Soldier 6&amp;quot;, &amp;quot;Rebel Soldier 7&amp;quot;, &amp;quot;Rebel Soldier 8&amp;quot;, &amp;quot;Rebel Soldier 9&amp;quot;, &amp;quot;Red 5&amp;quot;, &amp;quot;Red Leader&amp;quot;, &amp;quot;Saw Gerrera&amp;quot;, &amp;quot;Senator Jebel&amp;quot;, &amp;quot;Senator Vaspar&amp;quot;, &amp;quot;Sergeant Melshi&amp;quot;, &amp;quot;Ship Computer&amp;quot;, &amp;quot;Stormtrooper 1&amp;quot;, &amp;quot;Stormtrooper 2&amp;quot;, &amp;quot;Stormtrooper 3&amp;quot;, &amp;quot;Stormtrooper 4&amp;quot;, &amp;quot;Stormtrooper 5&amp;quot;, &amp;quot;Stormtrooper 6&amp;quot;, &amp;quot;Stormtrooper 7&amp;quot;, &amp;quot;Stormtrooper 8&amp;quot;, &amp;quot;Stormtrooper 9&amp;quot;, &amp;quot;Stormtrooper 10&amp;quot;, &amp;quot;Stormtrooper 11&amp;quot;, &amp;quot;Stormtrooper 12&amp;quot;, &amp;quot;Stormtrooper 13&amp;quot;, &amp;quot;Stormtrooper 14&amp;quot;, &amp;quot;Stormtrooper 15&amp;quot;, &amp;quot;Stormtrooper 16&amp;quot;, &amp;quot;Stormtrooper 17&amp;quot;, &amp;quot;Stormtrooper 18&amp;quot;, &amp;quot;Technician&amp;quot;, &amp;quot;Tivik&amp;quot;, &amp;quot;Unknown Senator&amp;quot;, &amp;quot;Unknown Senator 2&amp;quot;, &amp;quot;Vader&amp;quot;, &amp;quot;Vader&amp;#39;s Assistant&amp;quot;)

RO_females &amp;lt;- c(&amp;quot;Antenna Computer&amp;quot;, &amp;quot;Girl&amp;#39;s Mother&amp;quot;, &amp;quot;Jyn&amp;quot;, &amp;quot;Leia&amp;quot;, &amp;quot;Lyra&amp;quot;, &amp;quot;Mon Mothma&amp;quot;, &amp;quot;Rebel Pilot (Female)&amp;quot;, &amp;quot;Rebel Pilot (Female) 2&amp;quot;, &amp;quot;Rebel Pilot (Female) 3&amp;quot;, &amp;quot;Senator Pamlo&amp;quot;)


RO_full &amp;lt;- RO_full %&amp;gt;% 
            mutate(Gender = ifelse(Character %in% RO_females, &amp;quot;female&amp;quot;, 
                                ifelse(Character %in% RO_males, &amp;quot;male&amp;quot;, &amp;quot;unknown&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some questions I’ve already received about this process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What if a male character is voiced by a female actress (e.g., Tommy Pickles in Rugrats) or a female character is voiced by a male actor (e.g., Roz in Monster’s Inc.)?&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Well, in both of those cases, I’d have assigned the gender based on the pronouns used by other characters before getting to the actor/actress’ gender. The same methodology applies here. To my knowledge, I didn’t actually run into that problem with these movies. However, if an unnamed rhino was voiced by a female, I did assume it was a female rhino.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Can you really know the gender of an animated character?&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Nope! Again, I am relying on the other characters in the film to know what to call one another. This may be slightly flawed but it’s the best I can do with the information I have.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;counting-words&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Counting Words&lt;/h3&gt;
&lt;p&gt;Now that each of the characters has an assigned gender, it’s time to count how many words each character spoke. In R, I used the &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;stringi&lt;/code&gt; packages for this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Counting words per character
RO_full2 &amp;lt;- RO_full %&amp;gt;% 
                mutate(count = stri_count(Words, regex = &amp;quot;\\S+&amp;quot;)) %&amp;gt;% 
                group_by(Character, Gender) %&amp;gt;% 
                summarise(Total_Words = sum(count)) %&amp;gt;% 
                filter(!(Gender == &amp;quot;unknown&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I should note that I did not include a “minimum number of spoken words limit” to this project. So that means that any character that spoke even a single word is included. And yes, that means every stormtrooper that uttered at least one word will be in here.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualizing the Data&lt;/h2&gt;
&lt;div id=&#34;in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;In R&lt;/h3&gt;
&lt;div id=&#34;scatter-plot&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Scatter Plot&lt;/h4&gt;
&lt;p&gt;As a native R user, my first attempt to visualize all of this data was naturally in R. I started with a simple scatter plot for each movie. I had “Number of Turns Speaking” (i.e., the number of independent times that character’s name showed up) on the x-axis, “Total Number of Words Spoken” on the y-axis, and the “Total Number of Words Spoken” also mapped to circle size. I decided to use the &lt;code&gt;highcharter&lt;/code&gt; package and ended up with something like this:&lt;/p&gt;
&lt;iframe seamless src=&#34;../2016MovieDialogue_images/RO_fig/index.html&#34; width=&#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;Again, this is the figure for Rogue One, and we can see some potentially interesting things here. For instance, Cassian (the male lead) speaks more than Jyn (the female lead). It’s also easy to spot characters that are a bit more long-winded when they get to speak (Bodhi Rook and Galen) while others keep things short and to the point (Baze Malbus).&lt;/p&gt;
&lt;p&gt;I looked at these figures for each movie, and found a few other entertaining outliers. In The Jungle Book, Baloo spoke the most words, but also had fewer speaking opportunities than Mowgli. He rambled more than any other character in the movie (which, didn’t actually contain too much dialogue, overall).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../2016MovieDialogue_images/JB_Baloo.jpg&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There was another funny outlier in the Zootopia figure. This time, instead of the outlier belonging to a talkative bear, it belonged to a slow-talking sloth, Flash Slothmore. He spoke quite a few times, but didn’t actually say many words.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../2016MovieDialogue_images/Zootopia_Sloth.jpg&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, other than those few amusing findings, these figures weren’t helping me to see the number of speaking female characters amongst the entire speaking cast or the number of words each spoke, particularly because there were so many characters with so few words that they all overlapped.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bar-graph&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Bar Graph&lt;/h4&gt;
&lt;p&gt;Since the scatter plot didn’t work, I thought maybe a bar chart would. I plotted the characters along the X axis and total number of spoken words along the Y and (again for Rogue One) ended up with this:&lt;/p&gt;
&lt;iframe seamless src=&#34;../2016MovieDialogue_images/RO_fig2/index.html&#34; width=&#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;Still less than ideal. My biggest problem here is that there is such a big range between the main characters with lots of words and the minor characters with very few. Even in an interactive figure, you are required to zoom to get an idea of the smaller characters’ contributions.&lt;/p&gt;
&lt;p&gt;Needless to say, I wasn’t happy with the bar graph either.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;in-illustrator&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;In Illustrator&lt;/h3&gt;
&lt;p&gt;In the end, I decided to make an axis-free bubble chart. I should point out that I am perfectly aware of the arguments against bubble charts (look &lt;a href=&#34;http://junkcharts.typepad.com/junk_charts/2013/03/blowing-the-whistle-at-bubble-charts.html&#34;&gt;here&lt;/a&gt;), but in this case, I thought the visualization would be effective.&lt;/p&gt;
&lt;p&gt;The problem? I had no idea how to make an axis-free bubble chart in R.&lt;/p&gt;
&lt;p&gt;Before going down the rabbit-hole of making a new type of graphic in R, I decided to use my trusty Adobe Illustrator to quickly see what these visualizations might look like first. So I pulled my highcharter bubble charts into Illustrator and traced the circles to get an idea of relative size. I ended up with lots of groups of bubbles that looked like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../2016MovieDialogue_images/RO_V1.jpg&#34; width=&#34;30%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But there were a few issues with this. While I liked that you could easily spot the main characters, I knew that there were several characters in Rogue One who had fewer than 10 words, but their bubbles seemed to indicate more. I’d clearly have to alter how I sized the circles. It was also difficult to get an idea of what percentage of the characters or spoken words actually came from female characters.&lt;/p&gt;
&lt;p&gt;So, I adjusted the figure. I calculated the proper radius of a circle so that each circle’s &lt;a href=&#34;https://en.wikipedia.org/wiki/Bubble_chart#Choosing_bubble_sizes_correctly&#34;&gt;&lt;strong&gt;area&lt;/strong&gt;&lt;/a&gt; was scaled to the total number of words spoken by each character.&lt;/p&gt;
&lt;p&gt;I did this in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RO_full2 &amp;lt;- RO_full2 %&amp;gt;% 
            mutate(radius = sqrt(Total_Words),
                   diameter = radius*2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I could now manually enter the necessary diameter for each circle into Adobe Illustrator.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;While a full how-to for Adobe Illustrator design is outside the scope of this post, you can find lots of information on &lt;a href=&#34;https://helpx.adobe.com/illustrator/using/drawing-simple-lines-shapes.html&#34;&gt;Adobe’s site&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../2016MovieDialogue_images/RO_V2.jpg&#34; width=&#34;30%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That definitely helped make the circles a more reasonable size. Now to add some extra information, like the percentage of female characters and spoken words. Again, I calculated in R and added the data to Illustrator. I thought that the best way to display that information was just to put a circle around the bubbles, cut the circle, and color it to match the bubbles it was near. Then add a call-out of information. It looked like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../2016MovieDialogue_images/RO_V3.jpg&#34; width=&#34;30%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I was decently happy with it, until I (luckily) asked a friend to look at it. Her first response was asking about which percentage the pink outer line represented: the percentage of female characters or percentage of words spoken by females. It was an excellent question because, although I had intended the outer lines to be mostly decorative, they were so reminiscent of a pie or donut graph that we instinctively read it this way. So either I had to find a way to get the bubbles into “pie” pieces or get rid of the outer lines.&lt;/p&gt;
&lt;p&gt;Back to the drawing board.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-interactivity-with-d3.js&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Adding Interactivity with d3.js&lt;/h3&gt;
&lt;p&gt;While I was still trying to figure out the best way to show the overall character and word percentages for each movie, I ran into another issue. I loved the bubbles, but I wanted to know who each bubble represented. Where were my favorite characters in this bubble mass? I briefly toyed with the idea of adding an arrow with a character name to each bubble or trying to put names in the bubbles, but with so many characters and such a wide range of bubble sizes, I knew it would get too cluttered.&lt;/p&gt;
&lt;p&gt;Luckily for me, I had recently stumbled upon a fantastic data visualization collaboration called &lt;a href=&#34;http://www.datasketch.es/&#34;&gt;data sketch|es&lt;/a&gt;. I absolutely loved their unique data visualizations and the way they added interactive elements when necessary. After looking through their write-ups, I knew that interactivity, and more specifically: &lt;a href=&#34;https://en.wikipedia.org/wiki/Tooltip&#34;&gt;tooltips&lt;/a&gt;, were exactly what my visualization needed and it looked like the best way to do that would be using &lt;a href=&#34;https://d3js.org/&#34;&gt;d3.js&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, when I started this project, I had never once touched d3.js or Javascript. I used packages like &lt;code&gt;highcharter&lt;/code&gt; which wrapped Javascript and let me use it in R. When I first decided to add tooltips to this visualization I was hoping for something similar. I looked for a bridge between the programs I knew (R or Adobe Illustrator) and d3.js. I found that you could import .svg files from Illustrator into d3.js and add interactive tooltips to them, but all of the values had to be manually entered. That seemed like it was asking for typos.&lt;/p&gt;
&lt;p&gt;The more I looked, the more I realized I’d need to learn some d3.js to do this the way I want. So, to internet classes and StackOverflow I went. Somewhere along the line, I stumbled upon a &lt;a href=&#34;http://www.nytimes.com/interactive/2012/02/13/us/politics/2013-budget-proposal-graphic.html?_r=0&#34;&gt;fantastic interactive bubble chart&lt;/a&gt; from the New York Times and decided that if I was going to make my bubbles interactive, I also wanted to add the ability to separate them by gender. I was able to find a few excellent tutorials on how to make this happen (&lt;a href=&#34;https://www.youtube.com/watch?v=lPr60pexvEM&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://vallandingham.me/bubble_charts_with_d3v4.html&#34;&gt;here&lt;/a&gt;). So I played and experimented and played some more. When I got stuck I returned to Google searching and reading. At one point I was stuck on a problem for hours and could not find a workable solution, so I turned to the kind people of the internet, asked for &lt;a href=&#34;http://stackoverflow.com/questions/41479452/collision-detection-lost-after-toggle-d3v4&#34;&gt;help&lt;/a&gt;, and was lucky enough to have a very knowledgable user respond right away.&lt;/p&gt;
&lt;p&gt;I’m uploading my &lt;a href=&#34;https://github.com/ProQuestionAsker/ProQuestionAsker.github.io/blob/sources/content/projects/MovieDialogueInteractive/movie_bubbles2.js&#34;&gt;.js&lt;/a&gt;, &lt;a href=&#34;https://github.com/ProQuestionAsker/ProQuestionAsker.github.io/blob/sources/content/projects/MovieDialogueInteractive/style.css&#34;&gt;.css&lt;/a&gt;, and &lt;a href=&#34;https://github.com/ProQuestionAsker/ProQuestionAsker.github.io/blob/sources/content/projects/MovieDialogueInteractive/index.html&#34;&gt;.html&lt;/a&gt; files to Github, so anyone interested in exploring them, please do. As I learn more Javascript I hope to come back to this project and optimize the code. I know right now that it is far from perfect, but for my first project with d3.js, I’m very happy with how it turned out. To give some brief insight into parts of the d3.js code:&lt;/p&gt;
&lt;p&gt;I once again scale the circles by &lt;a href=&#34;https://github.com/d3/d3-scale/blob/master/README.md#scaleSqrt&#34;&gt;area&lt;/a&gt;, with a maximum circle diameter of 40 px.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var radiusScale = d3.scaleSqrt().domain([1, 4692]).range([1, 40])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I define a few &lt;a href=&#34;https://github.com/d3/d3/blob/master/API.md#forces-d3-force&#34;&gt;forces&lt;/a&gt; to move the circles throughout their .svg area (a 300 px by 300 px box). There are two separate X forces (forces that move the circles along the X axis) since I needed two conditions: all the bubbles combined and bubbles separated by gender.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;// Define the two forces along the X axis to split by gender
// the drawing force for males is at 30% of the width of the svg box
// the drawing force for females is at 70% of the width of the svg box
var forceXSplit = d3.forceX(d =&amp;gt; width * (d.Gender === &amp;quot;male&amp;quot; ? 0.3 : 0.7))
        .strength(0.2);

// Define the force along the X axis to combine all bubbles together 
// (at half the width of the svg box)
var forceXCombine = d3.forceX((width)/2).strength(0.1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, in order to keep the bubbles from overlapping one another, I added a &lt;a href=&#34;https://github.com/d3/d3-force/blob/master/README.md#forceCollide&#34;&gt;collision&lt;/a&gt; force. The radius of this force was scaled based on circle size so that larger circles pushed circles further from their center than smaller circles.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var forceCollide = d3.forceCollide(function(d){
        return radiusScale(d.Total_Words) + 1
      })
      .iterations(10);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With all of my forces defined, I could combine them in a &lt;a href=&#34;https://github.com/d3/d3-force/blob/master/README.md#forceSimulation&#34;&gt;simulation&lt;/a&gt; to determine the proper location of each bubble in the group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var simulation = d3.forceSimulation()
    .force(&amp;quot;x&amp;quot;, forceXCombine)
    .force(&amp;quot;y&amp;quot;, d3.forceY((height / 3) + 10).strength(0.15))
    .force(&amp;quot;collide&amp;quot;, forceCollide);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I just needed to include my data file so that each circle could be created automatically and sized according to the total number of words spoken by a character. At the same time, I added the tool tips that triggered when the user’s mouse hovered over a circle. Again, the tool tips were automatically filled with information from the data file.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Export data from R
write.csv(RO_full2, &amp;quot;RogueOne.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;// Import data into Javascript
d3.queue()
    .defer(d3.csv, &amp;quot;RogueOne.csv&amp;quot;)
    .await(ready)

function ready (error, datapoints) {
    datapoints.forEach(d =&amp;gt; d.Total_Words = +d.Total_Words);

    var mousemove = function() {
                return tooltip.style(&amp;quot;top&amp;quot;, (d3.event.pageY-10)+&amp;quot;px&amp;quot;).style(&amp;quot;left&amp;quot;,(d3.event.pageX+10)+&amp;quot;px&amp;quot;);
            }

  var mouseout = function(){return tooltip.style(&amp;quot;visibility&amp;quot;, &amp;quot;hidden&amp;quot;);} 

    var circles = svg.selectAll(&amp;quot;.Character&amp;quot;)
        .data(datapoints)
        .enter().append(&amp;quot;circle&amp;quot;)
        .attr(&amp;quot;class&amp;quot;, &amp;quot;Character&amp;quot;)
        .attr(&amp;quot;r&amp;quot;, function(d){
        return radiusScale(d.Total_Words)
    })
        .style(&amp;quot;fill&amp;quot;, d =&amp;gt; d.Gender === &amp;quot;male&amp;quot; ? &amp;quot;#3b3f93&amp;quot; : &amp;quot;#ff4a6b&amp;quot;)
        .on(&amp;quot;mouseover&amp;quot;, function(d) {
              tooltip.html(d.Character + &amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt; Words Spoken: &amp;quot; + d.Total_Words);
              tooltip.style(&amp;quot;visibility&amp;quot;, &amp;quot;visible&amp;quot;);
      })
      .on(&amp;quot;mousemove&amp;quot;, mousemove)
      .on(&amp;quot;mouseout&amp;quot;, mouseout);
}         &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I added a clickable element within each svg box to toggle between the combined and separated conditions for the bubbles. The style and functionality were inspired by the &lt;a href=&#34;http://jfmdev.github.io/SaVaGe/docs/toggle-switch.html&#34;&gt;toggle switch widget&lt;/a&gt; from the &lt;a href=&#34;http://jfmdev.github.io/SaVaGe/index.html&#34;&gt;SaVaGe&lt;/a&gt; library. I generated rectangles of sizes corresponding to the percentages of male and female characters and words spoken beneath my bubble grouping to give viewers an overall idea of representation within each movie. This percentage-wise stacked bar graph seemed to make the overarching trends clearest. I used &lt;a href=&#34;http://fontawesome.io/icons/&#34;&gt;Font Awesome&lt;/a&gt; icons alongside each bar graph to differentiate between character and word percentages. And that’s about it! The final design looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../2016MovieDialogue_images/FinalDesign.jpg&#34; width=&#34;30%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Again, the entire code used to generate the d3.js figure is available on my &lt;a href=&#34;https://github.com/ProQuestionAsker/ProQuestionAsker.github.io/tree/sources/content/projects/MovieDialogueInteractive&#34;&gt;Github&lt;/a&gt; and the interactive version is &lt;a href=&#34;https://ProQuestionAsker.github.io/projects/MovieDialogueInteractive/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;color-considerations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Color Considerations&lt;/h3&gt;
&lt;p&gt;Once I had my bubble charts working with their corresponding bar graphs, I needed to make a design decision: what color should these be? The simple/stereotypical answer when displaying genders (at least in the US) is “blue for boys and pink for girls”. I &lt;em&gt;really&lt;/em&gt; wanted to use a different color scheme. I’m not the biggest fan of the color dichotomy we use in America today and didn’t want to perpetuate it in my data visualization. So I tried a few other color schemes. I found beautiful color palettes on the following websites:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.colourlovers.com/&#34;&gt;ColourLovers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://coolors.co/&#34;&gt;Coolers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tools.medialab.sciences-po.fr/iwanthue/&#34;&gt;I Want Hue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dribbble.com/&#34;&gt;Dribbble&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But I ran into an issue. I must have tried hundreds of color schemes (many of which looked better with the background gray than the ones that I screenshot here).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../2016MovieDialogue_images/ColorScheme1.png&#34; width=&#34;30%&#34; height=&#34;200px&#34; /&gt;&lt;img src=&#34;../2016MovieDialogue_images/ColorScheme2.png&#34; width=&#34;30%&#34; height=&#34;200px&#34; /&gt;&lt;img src=&#34;../2016MovieDialogue_images/ColorScheme3.png&#34; width=&#34;30%&#34; height=&#34;200px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But regardless of the color scheme, I couldn’t easily tell which group represented males and which represented females. Yes, that’s what legends are for, but in the end, data visualization should be as easy to interpret as possible. In this case, that meant that some shade of blue and pink/red would be the easiest to understand. So, I found my favorite combination of the two and moved on.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;key-takeaways&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Key Takeaways&lt;/h2&gt;
&lt;p&gt;If you haven’t already checked out the interactive version, do that &lt;a href=&#34;https://ProQuestionAsker.github.io/projects/MovieDialogueInteractive/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Before I start this section, I feel the need to point out that I &lt;strong&gt;did not&lt;/strong&gt; do any statistics, machine learning, etc. on these data. I really set out on this project just to see if my impressions of female representation in 2016’s movies could be backed up by data and to find an interesting way to visualize it. If you’d like to do some more in-depth analytics yourself, I made the word-count data &lt;a href=&#34;&#34;&gt;available&lt;/a&gt;. &lt;em&gt;For legal reasons, I can’t post the transcripts themselves online.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now that I’ve got that out of the way, here are the key takeaways from this project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Highest Percentage of Female Characters&lt;/strong&gt;: Finding Dory (42% Female Characters)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lowest Percentage of Female Characters&lt;/strong&gt;: Rogue One (9% Female Characters)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highest Percentage of Female Dialogue&lt;/strong&gt;: Finding Dory (53% Female Dialogue)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lowest Percentage of Female Dialogue&lt;/strong&gt;: The Jungle Book (10% Female Dialogue)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;By Movie&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Captain America: Civil War&lt;/strong&gt;: Although this is titled a Captain America movie, Tony Stark (Ironman) speaks more than Steve Rogers (Captain America). Even with 2 female members of the “Avengers” team, this movie only had 16% female dialogue.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Finding Dory&lt;/strong&gt;: This movie scored the highest in both percentage of female characters and percentage of female dialogue, but it’s hard to not notice that most of the dialogue seems to revolve around Dory herself. She is the title character, but she alone accounts for 74% of the female dialogue and 39% of the movie’s dialogue overall. Alternatively, the “lead” male character, Marlin, only accounted for 32% of the male dialogue. Maybe Marlin wasn’t the male lead. It could have been Hank with 22% of the male dialogue. Or Bailey with 10%. Male dialogue in this movie is more well-spread amongst characters than female dialogue.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zootopia&lt;/strong&gt;: While there were still more male than female characters in this movie (38% female) the dialogue was close to equal (46% female). Like Finding Dory, the main character of this movie was female (Judy Hopps), and she accounts for 69% of the female dialogue. The main male character (Nick Wilde) says about 1000 fewer words than Judy Hopps, but also makes up only 43% of the male dialogue. In this case, the difference is likely due to the larger number of male characters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Jungle Book&lt;/strong&gt;: Although the writers clearly tried to make this movie more gender-equal than the original (by casting Scarlett Johansson as the voice of the historically-male snake, Kaa), it held the lowest amount of female dialogue (10%) and still only had 21% female characters. The male characters included the main, well-known ones (Mowgli, Bagheera, Baloo, King Louie, and Shere Khan) but also added a few new male speaking characters (e.g., a pangolin and squirrel that work with Baloo and a very possessive porcupine).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Secret Life of Pets&lt;/strong&gt;: This movie follows the daily journeys of two male dogs and their (mostly male) friends. It boasts a 27% female cast with 19% female dialogue.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Batman V. Superman&lt;/strong&gt;: The second superhero movie on this list has 24% female cast and 23% female dialogue. Notably (although, perhaps not surprisingly) Lex Luthor spoke the most in this movie, with Bruce Wayne (Batman) coming in 2nd. For a movie with two title characters, it’s worth pointing out that Superman only spoke 42% as many words as Batman.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rogue One&lt;/strong&gt;: My perceptions of this movie appeared to be just about correct, with Rogue One scoring the lowest percentage of female characters (9%). Of the 17% female dialogue, 78% came from the female lead: Jyn Erso. It’s also worth pointing out that Cassian (the male lead) spoke about 300 more words than Jyn.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deadpool&lt;/strong&gt;: The main character of this movie (Wade Wilson or Deadpool) said the most words of any character in this entire dataset (total of 4692). This may not be surprising because Deadpool is both the main/title character and the narrator of the movie, so he does talk quite frequently. His words make up 64% of the male dialogue in the movie.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fantastic Beasts&lt;/strong&gt;: While watching this movie, I really felt like there was relatively equal representation between male and female characters. However, when looking at the data, it appears only 32% of the characters and dialogue were attributed to females.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Suicide Squad&lt;/strong&gt;: Like Fantastic Beasts, I really thought this movie felt pretty equal. Amanda Waller (played by Viola Davis) is a strong, prevalent character, Harley Quinn (Margot Robbie) was advertised to be a main character, and there were several other female characters throughout the movie. However, when actually looking at the data, only 22% of the characters and 32% of the dialogue were female. Floyd/Deadshot (played by Will Smith) had the most dialogue throughout the film.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So although the gender distribution in &lt;a href=&#34;https://en.wikipedia.org/wiki/Human_sex_ratio&#34;&gt;humans&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Sex_ratio&#34;&gt;most animals&lt;/a&gt; worldwide is roughly 50/50, the closest any of the top 10 movies of 2016 got to gender equality was 58% male characters and 42% female characters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;future-work&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Future Work&lt;/h2&gt;
&lt;p&gt;While this project did validate my initial assumption (that there were very few females in Rogue One other than Jyn), I was incredibly surprised at the lack of gender equality throughout almost all of the top movies. These movies ranged by genre, target audience, release date (within 2016), and represented the worldwide highest grossing films (so we’re not looking only at the viewing habits of one country). Conducting this project was eye-opening for me and I hope to expand on it more in the future. Here’s what I’d love to add:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Character Race (this one is especially tricky, particularly for uncredited actors/actresses and animated films)&lt;/li&gt;
&lt;li&gt;Dialogue for top movies in years before 2016&lt;/li&gt;
&lt;li&gt;Look specifically at dialogue in movies with female leads (how does the dialogue distribution differ between those films and films with male leads?)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are reading this and are so inclined to start one of this projects yourself, please do!&lt;/p&gt;
&lt;p&gt;As always with my work, I appreciate feedback, so please either leave it in the comments section here, &lt;a href=&#34;https://twitter.com/ProQuesAsker&#34;&gt;tweet&lt;/a&gt; at me or email me &lt;a href=&#34;https://proquestionasker.github.io/contact/&#34;&gt;directly&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Dog Ownership in Seattle</title>
      <link>/projects/Seattle_Dogs/</link>
      <pubDate>Wed, 16 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/projects/Seattle_Dogs/</guid>
      <description>&lt;p&gt;Data cleaning, exploration, mapping, and data visualizations in RMarkdown.
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#importing-licensed-dog-ownership-data&#34;&gt;Importing Licensed Dog Ownership Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning-data&#34;&gt;Cleaning Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-visualizations&#34;&gt;Data Visualizations&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#dog-popularity----by-breed&#34;&gt;Dog Popularity &amp;ndash; By Breed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dog-popularity----by-size&#34;&gt;Dog Popularity &amp;ndash; By Size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dog-populations-by-zip-code&#34;&gt;Dog Populations by Zip Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dog-populations-by-size&#34;&gt;Dog Populations by Size&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#small&#34;&gt;Small&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#medium&#34;&gt;Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#large&#34;&gt;Large&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#giant&#34;&gt;Giant&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#caveats-of-dog-size-by-zipcode&#34;&gt;Caveats of Dog Size by Zipcode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dog-names&#34;&gt;Dog Names&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This report investigates licensed dog ownership in Seattle, WA (USA).&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m curious about a few things here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;People estimate that there are 160,000 dogs in Seattle. Where are they?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Seattle is a relatively densely-populated area. Are small, apartment-friendly dogs preferred?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Using this information, what recommendations could be made to aspiring dog sitters and walkers in Seattle?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I will annotate each step of data analysis as I go.&lt;/p&gt;

&lt;p&gt;Time to get started!&lt;/p&gt;

&lt;h3 id=&#34;loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# For mapping
library(choroplethr)
library(choroplethrZip)
library(ggmap)
library(mapproj)
library(zipcode)

# For data manipulation and tidying
library(dplyr)
library(tidyr)

# For data visualizations
library(ggplot2)
library(tm)
library(SnowballC)
library(wordcloud)

# For modeling and machine learning
library(caret)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;importing-licensed-dog-ownership-data&#34;&gt;Importing Licensed Dog Ownership Data&lt;/h3&gt;

&lt;p&gt;The spreadsheet containing all licensed dog ownership information was obtained from the Seattle Times article &lt;a href=&#34;http://www.seattletimes.com/life/pets/mapping-the-dogs-of-seattle/&#34;&gt;&amp;ldquo;Mapping the Dogs of Seattle&amp;rdquo;&lt;/a&gt; and is available for &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1XWLw_hxWM2RHiwALzcM_QxNpzQn_cDmS3Z9HFoZMvTo/edit#gid=460106206&#34;&gt;download&lt;/a&gt;. According to the article, the original data were obtained from the Seattle Animal Shelter and represent the 43,000 licensed dogs in Seattle as of February 2015. &lt;em&gt;Note: This number is thought to only represent approximately &lt;a href=&#34;http://www.seattle.gov/Documents/Departments/ParksAndRecreation/PoliciesPlanning/Plans/Response_to_SLI_69-1-B-1_(Dog_Off-Leash_Areas).pdf&#34;&gt;27% of the dog population in Seattle&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs &amp;lt;- read.csv(file = &amp;quot;Seattle_Dogs_2015.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Let&amp;rsquo;s take a quick look at the data file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(dogs)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    42996 obs. of  7 variables:
##  $ License.Type.Sold: Factor w/ 15 levels &amp;quot;Dog 6 Month Prov/Rabies&amp;quot;,..: 1 1 1 1 1 1 1 1 2 2 ...
##  $ Animal.Type      : Factor w/ 1 level &amp;quot;Dog&amp;quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Gender           : Factor w/ 3 levels &amp;quot;Female&amp;quot;,&amp;quot;Male&amp;quot;,..: 2 1 1 2 2 1 2 2 1 2 ...
##  $ Primary.Breed    : Factor w/ 227 levels &amp;quot;Affenpinscher&amp;quot;,..: 53 53 174 123 137 102 53 106 26 15 ...
##  $ Primary.Color    : Factor w/ 90 levels &amp;quot;&amp;quot;,&amp;quot;Amber&amp;quot;,&amp;quot;Apricot&amp;quot;,..: 85 6 85 10 10 9 9 36 83 56 ...
##  $ Name             : Factor w/ 10712 levels &amp;quot;&amp;quot;,&amp;quot; &amp;quot;,&amp;quot; Carlota&amp;quot;,..: 603 9763 317 1324 3671 5764 6065 4254 490 7006 ...
##  $ Zip.C            : Factor w/ 155 levels &amp;quot;&amp;quot;,&amp;quot;*/116&amp;quot;,&amp;quot;14534&amp;quot;,..: 107 107 100 75 84 1 86 77 107 87 ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like the variables we are working with right now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;License Type&lt;/strong&gt; : Indicates what type of license the dog has&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Animal Type&lt;/strong&gt; : Since this dataset is all about dogs, there is only one animal type listed: &amp;ldquo;Dog&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gender&lt;/strong&gt; : Dog&amp;rsquo;s sex (&amp;ldquo;Male&amp;rdquo;, &amp;ldquo;Female&amp;rdquo;, or &amp;ldquo;Unspec&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Primary Breed&lt;/strong&gt; : Indicates the general breed of the dog&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Primary Color&lt;/strong&gt; : Indicates the dog&amp;rsquo;s overall color&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Name&lt;/strong&gt; : Lists the dog&amp;rsquo;s name&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zip.C&lt;/strong&gt; : Indicates the zipcode where the dog is registered&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can eliminate the &amp;ldquo;Animal Type&amp;rdquo; column since it doesn&amp;rsquo;t give us any additional information.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs &amp;lt;- dogs %&amp;gt;% select(-2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, now is there anyway to condense or standardize the breeds listed?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at what kind of breeds are present in Seattle.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;levels(dogs$Primary.Breed)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;Affenpinscher&amp;quot;                  &amp;quot;Afghan Hound&amp;quot;                  
##   [3] &amp;quot;Airedale Terrier&amp;quot;               &amp;quot;Akita&amp;quot;                         
##   [5] &amp;quot;Alaskan Malumute&amp;quot;               &amp;quot;Amer. Pitbull Terrier&amp;quot;         
##   [7] &amp;quot;Amer. Water Spaniel&amp;quot;            &amp;quot;Amer.Staffordshire Terrier&amp;quot;    
##   [9] &amp;quot;American Eskimo&amp;quot;                &amp;quot;American Foxhound&amp;quot;             
##  [11] &amp;quot;Appenzel Mountain Dog&amp;quot;          &amp;quot;Australian Cattle Dog&amp;quot;         
##  [13] &amp;quot;Australian Kelpie&amp;quot;              &amp;quot;Australian Shepard&amp;quot;            
##  [15] &amp;quot;Australian Terrier&amp;quot;             &amp;quot;Basenji&amp;quot;                       
##  [17] &amp;quot;Basset Hound&amp;quot;                   &amp;quot;Beagle&amp;quot;                        
##  [19] &amp;quot;Bearded Collie&amp;quot;                 &amp;quot;Beauceron&amp;quot;                     
##  [21] &amp;quot;Belgian Malinios&amp;quot;               &amp;quot;Belgian Malinois&amp;quot;              
##  [23] &amp;quot;Belgian Sheepdog&amp;quot;               &amp;quot;Belgian Shepherd&amp;quot;              
##  [25] &amp;quot;Belgian Tervuren&amp;quot;               &amp;quot;Bernese Mountain Dog&amp;quot;          
##  [27] &amp;quot;Bichon Frise&amp;quot;                   &amp;quot;Bloodhound&amp;quot;                    
##  [29] &amp;quot;Blue Heeler&amp;quot;                    &amp;quot;Bordeaux Mastiff&amp;quot;              
##  [31] &amp;quot;Border Collie&amp;quot;                  &amp;quot;Border Terrier&amp;quot;                
##  [33] &amp;quot;Borzoi&amp;quot;                         &amp;quot;Boston Terrier&amp;quot;                
##  [35] &amp;quot;Bouvier De Flanders&amp;quot;            &amp;quot;Boxer&amp;quot;                         
##  [37] &amp;quot;Briard&amp;quot;                         &amp;quot;Brittany Spaniel&amp;quot;              
##  [39] &amp;quot;Brussels Griffon&amp;quot;               &amp;quot;Bull Terrier&amp;quot;                  
##  [41] &amp;quot;Bull Terrier, Minature&amp;quot;         &amp;quot;Bulldog&amp;quot;                       
##  [43] &amp;quot;Bulldog American&amp;quot;               &amp;quot;Bulldog English&amp;quot;               
##  [45] &amp;quot;Bullmastiff&amp;quot;                    &amp;quot;Cairn Terrier&amp;quot;                 
##  [47] &amp;quot;Canaan Dog&amp;quot;                     &amp;quot;Cane Corso&amp;quot;                    
##  [49] &amp;quot;Carolina&amp;quot;                       &amp;quot;Catahoula Leopard Dog&amp;quot;         
##  [51] &amp;quot;Cavalier King Charles Spaniel&amp;quot;  &amp;quot;Chesapeake Bay Retriever&amp;quot;      
##  [53] &amp;quot;Chihuahua&amp;quot;                      &amp;quot;Chihuahua, Long-haired&amp;quot;        
##  [55] &amp;quot;Chinese Crested&amp;quot;                &amp;quot;Chinook&amp;quot;                       
##  [57] &amp;quot;Chow Chow&amp;quot;                      &amp;quot;Cirneco Dell Etna&amp;quot;             
##  [59] &amp;quot;Clumber Spaniel&amp;quot;                &amp;quot;Cocker Spaniel&amp;quot;                
##  [61] &amp;quot;Cocker Spaniel, American&amp;quot;       &amp;quot;Cocker Spaniel, English&amp;quot;       
##  [63] &amp;quot;Collie&amp;quot;                         &amp;quot;Collie, Rough-Coated&amp;quot;          
##  [65] &amp;quot;Collie, Smooth-Coated&amp;quot;          &amp;quot;Coonhound&amp;quot;                     
##  [67] &amp;quot;Coonhound, Redbone&amp;quot;             &amp;quot;Coonhound, Walker&amp;quot;             
##  [69] &amp;quot;Corgi&amp;quot;                          &amp;quot;Corgi, Cardigan Welsh&amp;quot;         
##  [71] &amp;quot;Corgi, Pembroke Welsh&amp;quot;          &amp;quot;Coton de Tulear&amp;quot;               
##  [73] &amp;quot;Coton Retulear&amp;quot;                 &amp;quot;Curly-Coated Retriever&amp;quot;        
##  [75] &amp;quot;Curs&amp;quot;                           &amp;quot;Dachshund&amp;quot;                     
##  [77] &amp;quot;Dachshund, Long-Haired&amp;quot;         &amp;quot;Dachshund, Minature&amp;quot;           
##  [79] &amp;quot;Dachshund, Standard&amp;quot;            &amp;quot;Dachshund, Wirehaired&amp;quot;         
##  [81] &amp;quot;Dalmatian&amp;quot;                      &amp;quot;Dandie Dinmont Terrier&amp;quot;        
##  [83] &amp;quot;Dingo&amp;quot;                          &amp;quot;Doberman Pinscher&amp;quot;             
##  [85] &amp;quot;Dogo de Argentino&amp;quot;              &amp;quot;Dogue De Bordeaux&amp;quot;             
##  [87] &amp;quot;Elkhound&amp;quot;                       &amp;quot;English Foxhound&amp;quot;              
##  [89] &amp;quot;English Setter&amp;quot;                 &amp;quot;English Springer Spaniel&amp;quot;      
##  [91] &amp;quot;English Toy Spaniel&amp;quot;            &amp;quot;Entelbucher&amp;quot;                   
##  [93] &amp;quot;Field Spaniel&amp;quot;                  &amp;quot;Finnish Spitz&amp;quot;                 
##  [95] &amp;quot;Flat-Coated Retriever&amp;quot;          &amp;quot;Formosan Mountain Dog&amp;quot;         
##  [97] &amp;quot;Fox Terrier&amp;quot;                    &amp;quot;Fox Terrier, Smooth&amp;quot;           
##  [99] &amp;quot;Fox Terrier, Toy&amp;quot;               &amp;quot;Fox Terrier, Wirehaired&amp;quot;       
## [101] &amp;quot;French Bulldog&amp;quot;                 &amp;quot;German Shepherd&amp;quot;               
## [103] &amp;quot;German Shorthair Pointer&amp;quot;       &amp;quot;German Wirehair Pointer&amp;quot;       
## [105] &amp;quot;Giffon Vendeen&amp;quot;                 &amp;quot;Golden Retriever&amp;quot;              
## [107] &amp;quot;Goldendoodle&amp;quot;                   &amp;quot;Gordon Setter&amp;quot;                 
## [109] &amp;quot;Great Dane&amp;quot;                     &amp;quot;Great Pyrenees&amp;quot;                
## [111] &amp;quot;Greater Swiss Mountain Dog&amp;quot;     &amp;quot;Greyhound&amp;quot;                     
## [113] &amp;quot;Harrier&amp;quot;                        &amp;quot;Havanese&amp;quot;                      
## [115] &amp;quot;Hound&amp;quot;                          &amp;quot;Husky&amp;quot;                         
## [117] &amp;quot;Ibizan Hound&amp;quot;                   &amp;quot;Irish Setter&amp;quot;                  
## [119] &amp;quot;Irish Terrier&amp;quot;                  &amp;quot;Irish Wolfhound&amp;quot;               
## [121] &amp;quot;Italian Greyhound&amp;quot;              &amp;quot;Italian Spinone&amp;quot;               
## [123] &amp;quot;Jack Russell Terrier&amp;quot;           &amp;quot;Japanese Chin&amp;quot;                 
## [125] &amp;quot;Japanese Fox&amp;quot;                   &amp;quot;Kairn Terrier&amp;quot;                 
## [127] &amp;quot;Karelian Bear Dog&amp;quot;              &amp;quot;Keeshond&amp;quot;                      
## [129] &amp;quot;Kerry Blue Terrier&amp;quot;             &amp;quot;King Charles Spaniel&amp;quot;          
## [131] &amp;quot;Kookier Hound&amp;quot;                  &amp;quot;Korean Chin-do&amp;quot;                
## [133] &amp;quot;Kuvasz&amp;quot;                         &amp;quot;Kyileo&amp;quot;                        
## [135] &amp;quot;Lab Retriever&amp;quot;                  &amp;quot;Labradoodle&amp;quot;                   
## [137] &amp;quot;Labrador Retriever&amp;quot;             &amp;quot;Lakeland Terrier&amp;quot;              
## [139] &amp;quot;Landseer&amp;quot;                       &amp;quot;Leonberger&amp;quot;                    
## [141] &amp;quot;Lhaso Apso&amp;quot;                     &amp;quot;Looks Like&amp;quot;                    
## [143] &amp;quot;Lowchen&amp;quot;                        &amp;quot;Maltese&amp;quot;                       
## [145] &amp;quot;Manchester Terrier&amp;quot;             &amp;quot;Manchester Terrier, Toy&amp;quot;       
## [147] &amp;quot;Mastiff&amp;quot;                        &amp;quot;McNab&amp;quot;                         
## [149] &amp;quot;Mexican Hairless&amp;quot;               &amp;quot;Miniture Pinscher&amp;quot;             
## [151] &amp;quot;Mix&amp;quot;                            &amp;quot;Neapolitan Mastiff&amp;quot;            
## [153] &amp;quot;Newfoundland&amp;quot;                   &amp;quot;Norfolk Terrier&amp;quot;               
## [155] &amp;quot;Norwegian Elkhound&amp;quot;             &amp;quot;Norwegian Lundehund&amp;quot;           
## [157] &amp;quot;Norwich Terrier&amp;quot;                &amp;quot;Novia Scotia Duck Tolling Retr&amp;quot;
## [159] &amp;quot;NULL&amp;quot;                           &amp;quot;Old English Sheepdog&amp;quot;          
## [161] &amp;quot;Otterhound&amp;quot;                     &amp;quot;Papillon&amp;quot;                      
## [163] &amp;quot;Pekingese&amp;quot;                      &amp;quot;Pharaoh Hound&amp;quot;                 
## [165] &amp;quot;Pitbull&amp;quot;                        &amp;quot;Plott Hound&amp;quot;                   
## [167] &amp;quot;Pointer&amp;quot;                        &amp;quot;Pointing Griffon, Wirehaired&amp;quot;  
## [169] &amp;quot;Pomeranian&amp;quot;                     &amp;quot;Poodle&amp;quot;                        
## [171] &amp;quot;Poodle, Minature&amp;quot;               &amp;quot;Poodle, Standard&amp;quot;              
## [173] &amp;quot;Poodle, Teacup&amp;quot;                 &amp;quot;Poodle, Toy&amp;quot;                   
## [175] &amp;quot;Portuguese Water Dog&amp;quot;           &amp;quot;Pug&amp;quot;                           
## [177] &amp;quot;Puli&amp;quot;                           &amp;quot;Purebred&amp;quot;                      
## [179] &amp;quot;Queensland Blue Heeler&amp;quot;         &amp;quot;Red Heeler&amp;quot;                    
## [181] &amp;quot;Rhodesian Ridgeback&amp;quot;            &amp;quot;Rottweiler&amp;quot;                    
## [183] &amp;quot;Saint Bernard&amp;quot;                  &amp;quot;Saluki&amp;quot;                        
## [185] &amp;quot;Samoyed&amp;quot;                        &amp;quot;Schipperke&amp;quot;                    
## [187] &amp;quot;Schnauzer&amp;quot;                      &amp;quot;Schnauzer, Giant&amp;quot;              
## [189] &amp;quot;Schnauzer, Minature&amp;quot;            &amp;quot;Schnauzer, Standard&amp;quot;           
## [191] &amp;quot;Scottish Deerhound&amp;quot;             &amp;quot;Scottish Terrier&amp;quot;              
## [193] &amp;quot;Sealyham Terrier&amp;quot;               &amp;quot;See Notes&amp;quot;                     
## [195] &amp;quot;Setter&amp;quot;                         &amp;quot;Shar-Pei&amp;quot;                      
## [197] &amp;quot;Shepherd&amp;quot;                       &amp;quot;Shetland Sheepdog&amp;quot;             
## [199] &amp;quot;Shiba Inu&amp;quot;                      &amp;quot;Shih Tzu&amp;quot;                      
## [201] &amp;quot;Siberian Husky&amp;quot;                 &amp;quot;Silken Windhound&amp;quot;              
## [203] &amp;quot;Silky Terrier&amp;quot;                  &amp;quot;Spaniel&amp;quot;                       
## [205] &amp;quot;Springer Spaniel&amp;quot;               &amp;quot;Staffordshire Bull Terrier&amp;quot;    
## [207] &amp;quot;Sussex Spaniel&amp;quot;                 &amp;quot;Terrier&amp;quot;                       
## [209] &amp;quot;Terrier, Black Russian&amp;quot;         &amp;quot;Terrier, Rat&amp;quot;                  
## [211] &amp;quot;Terrier, Soft-Coated Wheaten&amp;quot;   &amp;quot;Tibetan Mastiff&amp;quot;               
## [213] &amp;quot;Tibetan Spaniel&amp;quot;                &amp;quot;Tibetan Terrier&amp;quot;               
## [215] &amp;quot;Unspecified&amp;quot;                    &amp;quot;Vizsla&amp;quot;                        
## [217] &amp;quot;Water Spaniel&amp;quot;                  &amp;quot;Weimaraner&amp;quot;                    
## [219] &amp;quot;Welsh Springer Spaniel&amp;quot;         &amp;quot;Welsh Terrier&amp;quot;                 
## [221] &amp;quot;West Highland Terrier&amp;quot;          &amp;quot;West Highland White Terrier&amp;quot;   
## [223] &amp;quot;West Hihgland White Terrier&amp;quot;    &amp;quot;Whippet&amp;quot;                       
## [225] &amp;quot;Wirehair Terrier&amp;quot;               &amp;quot;Wolf Hybrid&amp;quot;                   
## [227] &amp;quot;Yorkshire Terrier&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wow! That&amp;rsquo;s quite a few! We&amp;rsquo;ll come back to cleaning up the species names in a bit.&lt;/p&gt;

&lt;p&gt;Generally, the dog&amp;rsquo;s estimated size may be more beneficial than their breed, so let&amp;rsquo;s try to pair these data up with information from other sources. The data used are available &lt;a href=&#34;http://modernpuppies.com/breedweightchart.aspx&#34;&gt;here&lt;/a&gt;. Time to import the database of dog breeds with their sizes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weight &amp;lt;- read.csv(file = &amp;quot;Breed_Wt.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s see what that looks like.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(weight)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    372 obs. of  3 variables:
##  $ Breed                 : chr  &amp;quot;Airedoodle&amp;quot; &amp;quot;Alapaha Blue Blood Bulldog&amp;quot; &amp;quot;Alaskan Klee Kai&amp;quot; &amp;quot;Alsatian&amp;quot; ...
##  $ Average.Adult.Weight  : chr  &amp;quot;Male: 45-65 lbs&amp;quot; &amp;quot;Male: 50-80 lbs&amp;quot; &amp;quot;Male: 11-15 lbs&amp;quot; &amp;quot;Male: 65-85 lbs&amp;quot; ...
##  $ Average.Adult.Weight.1: chr  &amp;quot;Female: 45-65 lbs&amp;quot; &amp;quot;Female: 50-80 lbs&amp;quot; &amp;quot;Female: 11-15 lbs&amp;quot; &amp;quot;Female: 50-70 lbs&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(weight)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                        Breed Average.Adult.Weight Average.Adult.Weight.1
## 1                 Airedoodle      Male: 45-65 lbs      Female: 45-65 lbs
## 2 Alapaha Blue Blood Bulldog      Male: 50-80 lbs      Female: 50-80 lbs
## 3           Alaskan Klee Kai      Male: 11-15 lbs      Female: 11-15 lbs
## 4                   Alsatian      Male: 65-85 lbs      Female: 50-70 lbs
## 5           American Bulldog      Male: 45-75 lbs      Female: 45-75 lbs
## 6               Aussiedoodle     Male: 35-65 lbs       Female: 25-55 lbs
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cleaning-data&#34;&gt;Cleaning Data&lt;/h2&gt;

&lt;p&gt;Looks like lots of character strings. Time to split out some of these columns. We&amp;rsquo;ll use the R packages &lt;code&gt;tidyr&lt;/code&gt; and &lt;code&gt;dplyr&lt;/code&gt; for this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Delete empty rows
weight &amp;lt;- weight[!apply(weight == &amp;quot;&amp;quot;, 1, all), ]

# Splitting Average Adult Weight (Species with Weight Ranges)
weight_split &amp;lt;- weight %&amp;gt;% separate(Average.Adult.Weight, into = c(&amp;quot;Male&amp;quot;, 
    &amp;quot;Wt_Range&amp;quot;), sep = &amp;quot;: &amp;quot;) %&amp;gt;% filter(grepl(&amp;quot;-&amp;quot;, Wt_Range)) %&amp;gt;% 
    separate(Wt_Range, into = c(&amp;quot;Min&amp;quot;, &amp;quot;Max&amp;quot;, &amp;quot;lbs&amp;quot;)) %&amp;gt;% select(-lbs) %&amp;gt;% 
    separate(Average.Adult.Weight.1, into = c(&amp;quot;Female&amp;quot;, &amp;quot;Wt_Range_F&amp;quot;), 
        sep = &amp;quot;: &amp;quot;) %&amp;gt;% filter(grepl(&amp;quot;-&amp;quot;, Wt_Range_F)) %&amp;gt;% separate(Wt_Range_F, 
    into = c(&amp;quot;Min_F&amp;quot;, &amp;quot;Max_F&amp;quot;, &amp;quot;lbs_F&amp;quot;)) %&amp;gt;% mutate_each(funs(as.numeric), 
    (Min:Max)) %&amp;gt;% mutate_each(funs(as.numeric), (Min_F:Max_F)) %&amp;gt;% 
    mutate(Male_Avg = (Min + Max)/2) %&amp;gt;% mutate(Female_Avg = (Min_F + 
    Max_F)/2) %&amp;gt;% select(1, 9:10)

# Splitting Average Adult Weight (no ranges)
weight_split_2 &amp;lt;- weight %&amp;gt;% separate(Average.Adult.Weight, into = c(&amp;quot;Male&amp;quot;, 
    &amp;quot;Wt_Range&amp;quot;), sep = &amp;quot;: &amp;quot;) %&amp;gt;% filter(!grepl(&amp;quot;-&amp;quot;, Wt_Range)) %&amp;gt;% 
    separate(Wt_Range, into = c(&amp;quot;Male_Avg&amp;quot;, &amp;quot;lbs&amp;quot;)) %&amp;gt;% separate(Average.Adult.Weight.1, 
    into = c(&amp;quot;Female&amp;quot;, &amp;quot;Wt_Range_F&amp;quot;), sep = &amp;quot;: &amp;quot;) %&amp;gt;% separate(Wt_Range_F, 
    into = c(&amp;quot;Female_Avg&amp;quot;, &amp;quot;lbs_2&amp;quot;)) %&amp;gt;% select(1, 3, 6)

# Bind Both Data Frames
weight_split_all &amp;lt;- rbind(weight_split_2, weight_split)

# Check out our new dataframe
head(weight_split_all)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##              Breed Male_Avg Female_Avg
## 1     Afghan Hound       60         50
## 2 Airedale Terrier       55         55
## 3 Alaskan Malamute       85         75
## 4          Basenji       24         22
## 5  English Bulldog       50         40
## 6    Cairn Terrier       14         13
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Now we have a dataframe that just lists breed, and then average weight for males and females. Now we can use this to fill in the estimated weight for each of the animals in our &lt;code&gt;dogs&lt;/code&gt; dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Make a copy of our dataset
dogs_2 &amp;lt;- dogs

# Match dog breed from dogs dataset to breed from
# weight_split_all dataset
dogs_2$Male_Avg &amp;lt;- weight_split_all[match(dogs_2$Primary.Breed, 
    weight_split_all$Breed), &amp;quot;Male_Avg&amp;quot;]

dogs_2$Male_Avg &amp;lt;- as.numeric(dogs_2$Male_Avg)

dogs_2$Female_Avg &amp;lt;- weight_split_all[match(dogs_2$Primary.Breed, 
    weight_split_all$Breed), &amp;quot;Female_Avg&amp;quot;]

dogs_2$Female_Avg &amp;lt;- as.numeric(dogs_2$Female_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Let&amp;rsquo;s check how we did.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(dogs_2$Male_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    5.00   16.00   52.50   47.53   72.50  182.50   11611
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Well, looks like our system automatically placed 73% of our entries, the remaining 27% (or 11,611 dogs) were not found. Let&amp;rsquo;s see if those were all the same or similar species.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;missing_size &amp;lt;- dogs_2 %&amp;gt;% filter(is.na(Male_Avg)) %&amp;gt;% group_by(Primary.Breed) %&amp;gt;% 
    summarise(count = n())

head(missing_size)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 2
##                Primary.Breed count
##                       &amp;lt;fctr&amp;gt; &amp;lt;int&amp;gt;
## 1           Alaskan Malumute   123
## 2      Amer. Pitbull Terrier   137
## 3        Amer. Water Spaniel     5
## 4 Amer.Staffordshire Terrier   186
## 5      Appenzel Mountain Dog     3
## 6         Australian Shepard  1216
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ah, looks like we have a few misspelled names in our original database. Let&amp;rsquo;s try to clean those up a bit.&lt;/p&gt;

&lt;p&gt;Due to the random nature of the misspellings and re-wording of breeds in this dataset, I&amp;rsquo;ll use the &lt;code&gt;gsub&lt;/code&gt; function to manually recode the ones that need it. This also allows for verification that the correct new term is being used.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Fixing Misspellings
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Alaskan Malumute&amp;quot;, &amp;quot;Alaskan Malamute&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Shepard&amp;quot;, &amp;quot;Shepherd&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Belgian Malinios&amp;quot;, &amp;quot;Belgian Malinois&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bouvier De Flanders&amp;quot;, &amp;quot;Bouvier des Flandres&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Coton Retulear&amp;quot;, &amp;quot;Coton de Tulear&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Dogo de Argentino&amp;quot;, &amp;quot;Dogo Argentino&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Entelbucher&amp;quot;, &amp;quot;Entlebucher&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;German Shorthair Pointer&amp;quot;, &amp;quot;German Shorthaired Pointer&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;German Wirehair Pointer&amp;quot;, &amp;quot;German Wirehaired Pointer&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Giffon Vendeen&amp;quot;, &amp;quot;Griffon Vendeen&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Italian Spinone&amp;quot;, &amp;quot;Spinone Italiano&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Kairn Terrier&amp;quot;, &amp;quot;Cairn Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Kookier Hound&amp;quot;, &amp;quot;Kooikerhondje&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Korean Chin-do&amp;quot;, &amp;quot;Jindo&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Kyileo&amp;quot;, &amp;quot;Kyi-Leo&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Lhaso Apso&amp;quot;, &amp;quot;Lhasa Apso&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Miniture Pinscher&amp;quot;, &amp;quot;Miniature Pinscher&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Novia Scotia Duck Tolling Retr&amp;quot;, 
    &amp;quot;Nova Scotia Duck Tolling Retriever&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Setter$&amp;quot;, &amp;quot;English Setter&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;West Hihgland White Terrier|West Highland White Terrier&amp;quot;, 
    &amp;quot;West Highland Terrier&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Amer.Staffordshire Terrier&amp;quot;, &amp;quot;American Staffordshire Terrier&amp;quot;, 
    dogs_2$Primary.Breed)

# Change any &#39;Amer.&#39; to &#39;American&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Amer\\.$&amp;quot;, &amp;quot;American&amp;quot;, dogs_2$Primary.Breed, 
    fixed = TRUE)

# Another name for Bordeaux Mastiff is &#39;French Mastiff&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bordeaux Mastiff|Dogue De Bordeaux&amp;quot;, 
    &amp;quot;French Mastiff&amp;quot;, dogs_2$Primary.Breed)

# Change &#39;Elkhound&#39; to &#39;Norwegian Elkhound&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Elkhound$&amp;quot;, &amp;quot;Norwegian Elkhound&amp;quot;, 
    dogs_2$Primary.Breed)

# Change &#39;Husky&#39; to &#39;Siberian Husky&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Husky$&amp;quot;, &amp;quot;Siberian Husky&amp;quot;, dogs_2$Primary.Breed)

# Change King Charles Spaniel to Cavalier King Charles
# Spaniel
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;King Charles Spaniel|Cavalier King Charles Spaniel&amp;quot;, 
    &amp;quot;Cavalier King Charles Spaniel&amp;quot;, dogs_2$Primary.Breed)

# Change Lab Retriever to Labrador Retriever
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Lab Retriever&amp;quot;, &amp;quot;Labrador Retriever&amp;quot;, 
    dogs_2$Primary.Breed)

# Mexican Hairless are also called &#39;Xolo&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Mexican Hairless&amp;quot;, &amp;quot;Xolo&amp;quot;, dogs_2$Primary.Breed)

# Queensland Blue Heelers and Red Heelers are more commonly
# known as Australian Cattle Dogs
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Queensland Blue Heeler|Red Heeler&amp;quot;, 
    &amp;quot;Australian Cattle Dog&amp;quot;, dogs_2$Primary.Breed)

# Water Spaniels are the same as American Water Spaniels
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Amer\\. Water Spaniel|^Water Spaniel$&amp;quot;, 
    &amp;quot;American Water Spaniel&amp;quot;, dogs_2$Primary.Breed)

# Japanese Foxes are also called &#39;Shiba Inu&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Japanese Fox&amp;quot;, &amp;quot;Shiba Inu&amp;quot;, dogs_2$Primary.Breed)

# Changing the order of some words
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bull Terrier, Minature&amp;quot;, &amp;quot;Miniature Bull Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bulldog American&amp;quot;, &amp;quot;American Bulldog&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bulldog English&amp;quot;, &amp;quot;English Bulldog&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Cocker Spaniel, American&amp;quot;, &amp;quot;American Cocker Spaniel&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Cocker Spaniel, English&amp;quot;, &amp;quot;English Cocker Spaniel&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Corgi, Cardigan Welsh&amp;quot;, &amp;quot;Cardigan Welsh Corgi&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Corgi, Pembroke Welsh&amp;quot;, &amp;quot;Pembroke Welsh Corgi&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Dachshund, Minature&amp;quot;, &amp;quot;Miniature Dachshund&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Fox Terrier, Toy&amp;quot;, &amp;quot;Toy Fox Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Manchester Terrier, Toy&amp;quot;, &amp;quot;Toy Manchester Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Pointing Griffon, Wirehaired&amp;quot;, 
    &amp;quot;Wirehaired Pointing Griffon&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Poodle, Minature&amp;quot;, &amp;quot;Miniature Poodle&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Schnauzer, Giant&amp;quot;, &amp;quot;Giant Schnauzer&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Schnauzer, Minature&amp;quot;, &amp;quot;Miniature Schnauzer&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Terrier, Black Russian&amp;quot;, &amp;quot;Black Russian Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Terrier, Rat&amp;quot;, &amp;quot;Rat Terrier&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Terrier, Soft-Coated Wheaten&amp;quot;, 
    &amp;quot;Soft Coated Wheaten Terrier&amp;quot;, dogs_2$Primary.Breed)

# Combine similar types
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Collie, Rough-Coated|Collie, Smooth-Coated&amp;quot;, 
    &amp;quot;Collie&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Chihuahua, Long-haired&amp;quot;, &amp;quot;Chihuahua&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Coonhound, Redbone|Coonhound, Walker&amp;quot;, 
    &amp;quot;Coonhound&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Dachshund, Long-Haired|Dachshund, Standard|Dachshund, Wirehaired|^Dachshund$&amp;quot;, 
    &amp;quot;Standard Dachshund&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Fox Terrier$|Fox Terrier, Smooth|Fox Terrier, Wirehaired|Wirehair Terrier&amp;quot;, 
    &amp;quot;Standard Fox Terrier&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Poodle$|Poodle, Standard&amp;quot;, &amp;quot;Standard Poodle&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Poodle, Teacup|Poodle, Toy&amp;quot;, &amp;quot;Toy Poodle&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Schnauzer$|Schnauzer, Standard&amp;quot;, 
    &amp;quot;Standard Schnauzer&amp;quot;, dogs_2$Primary.Breed)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That was a lot of very different errors in that dataset! Let&amp;rsquo;s see if that helped.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Match dog breed from dogs dataset to breed from
# weight_split_all dataset
dogs_2$Male_Avg &amp;lt;- weight_split_all[match(dogs_2$Primary.Breed, 
    weight_split_all$Breed), &amp;quot;Male_Avg&amp;quot;]

dogs_2$Male_Avg &amp;lt;- as.numeric(dogs_2$Male_Avg)

dogs_2$Female_Avg &amp;lt;- weight_split_all[match(dogs_2$Primary.Breed, 
    weight_split_all$Breed), &amp;quot;Female_Avg&amp;quot;]

dogs_2$Female_Avg &amp;lt;- as.numeric(dogs_2$Female_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see how we did.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(dogs_2$Male_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    5.00   15.50   50.00   45.19   72.50  182.50    3503
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Well, that did fix some of the missing values! Still another 3,503 (or 8%) to go!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;missing_size_2 &amp;lt;- dogs_2 %&amp;gt;% filter(is.na(Male_Avg)) %&amp;gt;% group_by(Primary.Breed) %&amp;gt;% 
    summarise(count = n())

missing_size_2$Primary.Breed
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Amer. Pitbull Terrier&amp;quot;  &amp;quot;Appenzel Mountain Dog&amp;quot; 
##  [3] &amp;quot;Belgian Shepherd&amp;quot;       &amp;quot;Bulldog&amp;quot;               
##  [5] &amp;quot;Carolina&amp;quot;               &amp;quot;Cirneco Dell Etna&amp;quot;     
##  [7] &amp;quot;Curs&amp;quot;                   &amp;quot;Dingo&amp;quot;                 
##  [9] &amp;quot;Entlebucher&amp;quot;            &amp;quot;Formosan Mountain Dog&amp;quot; 
## [11] &amp;quot;Hound&amp;quot;                  &amp;quot;Kyi-Leo&amp;quot;               
## [13] &amp;quot;Landseer&amp;quot;               &amp;quot;Looks Like&amp;quot;            
## [15] &amp;quot;McNab&amp;quot;                  &amp;quot;Mix&amp;quot;                   
## [17] &amp;quot;Norwegian Lundehund&amp;quot;    &amp;quot;NULL&amp;quot;                  
## [19] &amp;quot;Purebred&amp;quot;               &amp;quot;Saluki&amp;quot;                
## [21] &amp;quot;See Notes&amp;quot;              &amp;quot;Shepherd&amp;quot;              
## [23] &amp;quot;Silken Windhound&amp;quot;       &amp;quot;Spaniel&amp;quot;               
## [25] &amp;quot;Terrier&amp;quot;                &amp;quot;Toy Manchester Terrier&amp;quot;
## [27] &amp;quot;Unspecified&amp;quot;            &amp;quot;Welsh Springer Spaniel&amp;quot;
## [29] &amp;quot;Wolf Hybrid&amp;quot;            &amp;quot;Xolo&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like a few of these can&amp;rsquo;t be sorted. For example, we have no way of estimating size for &amp;ldquo;Looks Like&amp;rdquo;, &amp;ldquo;Mix&amp;rdquo;, &amp;ldquo;Purebred&amp;rdquo;, &amp;ldquo;See Notes&amp;rdquo; or &amp;ldquo;Unspecified&amp;rdquo;, so I&amp;rsquo;ll make the sizes of all of those &amp;ldquo;NA&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Looks Like|^Mix$|NULL|Purebred|See Notes|Unspecified|^Curs$&amp;quot;, 
    NA, dogs_2$Primary.Breed)

# Calculate how many are missing now
missing_size_3 &amp;lt;- dogs_2 %&amp;gt;% filter(is.na(Male_Avg)) %&amp;gt;% group_by(Primary.Breed) %&amp;gt;% 
    summarise(count = n())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So of our remaining 3,503 dogs, how many of them have sizes that we can&amp;rsquo;t estimate?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;missing_size_3[which(is.na(missing_size_3)), ]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   Primary.Breed count
##           &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
## 1          &amp;lt;NA&amp;gt;  1313
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can&amp;rsquo;t estimate 1,313 dogs&amp;rsquo; sizes, which means that we can still estimate the size of the remaining 2,190 dogs. We only have a few species left, and it looks like they weren&amp;rsquo;t ones that were in our original weights dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;missing_size_3$Primary.Breed
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Amer. Pitbull Terrier&amp;quot;  &amp;quot;Appenzel Mountain Dog&amp;quot; 
##  [3] &amp;quot;Belgian Shepherd&amp;quot;       &amp;quot;Bulldog&amp;quot;               
##  [5] &amp;quot;Carolina&amp;quot;               &amp;quot;Cirneco Dell Etna&amp;quot;     
##  [7] &amp;quot;Dingo&amp;quot;                  &amp;quot;Entlebucher&amp;quot;           
##  [9] &amp;quot;Formosan Mountain Dog&amp;quot;  &amp;quot;Hound&amp;quot;                 
## [11] &amp;quot;Kyi-Leo&amp;quot;                &amp;quot;Landseer&amp;quot;              
## [13] &amp;quot;McNab&amp;quot;                  &amp;quot;Norwegian Lundehund&amp;quot;   
## [15] &amp;quot;Saluki&amp;quot;                 &amp;quot;Shepherd&amp;quot;              
## [17] &amp;quot;Silken Windhound&amp;quot;       &amp;quot;Spaniel&amp;quot;               
## [19] &amp;quot;Terrier&amp;quot;                &amp;quot;Toy Manchester Terrier&amp;quot;
## [21] &amp;quot;Welsh Springer Spaniel&amp;quot; &amp;quot;Wolf Hybrid&amp;quot;           
## [23] &amp;quot;Xolo&amp;quot;                   NA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since there are only a few breeds left, I will manually create a database of the average weights (all found on the Wikipedia pages for the species).&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll upload in the supplemental file and match the breed name and mass.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Import File
supp_weight &amp;lt;- read.csv(file = &amp;quot;Supp_Breed_Wt.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = FALSE)

# Make a copy of our filtered dataset
dogs_3 &amp;lt;- dogs_2 %&amp;gt;% filter(is.na(Male_Avg))

dogs_4 &amp;lt;- dogs_2 %&amp;gt;% filter(!is.na(Male_Avg))

# Match dog breed from dogs dataset to breed from
# weight_split_all dataset
dogs_3$Male_Avg &amp;lt;- supp_weight[match(dogs_3$Primary.Breed, supp_weight$Breed), 
    &amp;quot;Male_Avg&amp;quot;]

dogs_3$Male_Avg &amp;lt;- as.numeric(dogs_3$Male_Avg)

dogs_3$Female_Avg &amp;lt;- supp_weight[match(dogs_3$Primary.Breed, 
    supp_weight$Breed), &amp;quot;Female_Avg&amp;quot;]

dogs_3$Female_Avg &amp;lt;- as.numeric(dogs_3$Female_Avg)

# Bind datasets back together
dogs_5 &amp;lt;- rbind(dogs_3, dogs_4)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(dogs_5$Male_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    5.00   16.00   50.00   45.77   72.50  182.50    1313
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Awesome! So the only dogs that we still don&amp;rsquo;t have approximate weights on are the ones with miscoded breeds. Now let&amp;rsquo;s get a better approximation of weight based on gender.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs_5$Gender &amp;lt;- as.factor(dogs_5$Gender)

dogs_5 &amp;lt;- dogs_5 %&amp;gt;% mutate(weight = ifelse(Gender == &amp;quot;Female&amp;quot;, 
    Female_Avg, Male_Avg))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect. Now we can make an estimate of how they would be categorized on &amp;ldquo;&lt;a href=&#34;www.rover.com&#34;&gt;Rover.com&lt;/a&gt;&amp;rdquo;, a Seattle-based website aimed at helping dog-owners find reliable dog-sitters and walkers. Their website lists the following size cutoffs (in lbs):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Small = 0 - 15&lt;/li&gt;
&lt;li&gt;Medium = 16 - 40&lt;/li&gt;
&lt;li&gt;Large = 41 - 100&lt;/li&gt;
&lt;li&gt;Giant = 100 +&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&amp;rsquo;s add those classifications to our dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs_5 &amp;lt;- dogs_5 %&amp;gt;% mutate(size_class = ifelse(weight &amp;lt;= 15, 
    &amp;quot;Small&amp;quot;, ifelse(weight &amp;gt; 15 &amp;amp; weight &amp;lt;= 40, &amp;quot;Medium&amp;quot;, ifelse(weight &amp;gt; 
        40 &amp;amp; weight &amp;lt;= 100, &amp;quot;Large&amp;quot;, ifelse(weight &amp;gt; 100, &amp;quot;Giant&amp;quot;, 
        NA)))))

dogs_5$size_class &amp;lt;- as.factor(dogs_5$size_class)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;ve got information on dogs, with their breeds, zipcodes and approximate sizes and size classes. This will help us later.&lt;/p&gt;

&lt;h2 id=&#34;data-visualizations&#34;&gt;Data Visualizations&lt;/h2&gt;

&lt;h3 id=&#34;dog-popularity-by-breed&#34;&gt;Dog Popularity &amp;ndash; By Breed&lt;/h3&gt;

&lt;p&gt;Now let&amp;rsquo;s look at some visualizations. We&amp;rsquo;ll start with the popularity of each dog breed within Seattle. This figure shows the top 24 most popular breeds in the city.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-23-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Looks like labrador retrievers are by far the most popular breed of dog in Seattle.&lt;/p&gt;

&lt;h3 id=&#34;dog-popularity-by-size&#34;&gt;Dog Popularity &amp;ndash; By Size&lt;/h3&gt;

&lt;p&gt;How do the numbers of dogs break down by dog size?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-24-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For a city filled with apartment buildings, Seattle-ites really love large dogs (almost as much as medium and small dogs combined!).&lt;/p&gt;

&lt;p&gt;I wonder if this trend varies depending on which part of the city the pets are living in.&lt;/p&gt;

&lt;h3 id=&#34;dog-populations-by-zip-code&#34;&gt;Dog Populations by Zip Code&lt;/h3&gt;

&lt;p&gt;First let&amp;rsquo;s see the density of dogs living in each zip code. Looks like we have some messy zip code data with quite a few zip codes not falling in the Seattle area. We&amp;rsquo;ll use a list of &lt;a href=&#34;http://www.unitedstateszipcodes.org/wa/#zips-list&#34;&gt;Washington State zip codes&lt;/a&gt; to narrow this list down.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Import Zipcode dataset
zipcodes &amp;lt;- read.csv(&amp;quot;Zipcodes.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)

# Match zipcodes in database to those listed on dog licenses
dogs_5$zip &amp;lt;- zipcodes[match(dogs_5$Zip.C, zipcodes$ZIP), &amp;quot;ZIP&amp;quot;]

# Make zipcodes factors
dogs_5$zip &amp;lt;- as.factor(dogs_5$zip)

# How many are missing?
sum(is.na(dogs_5$zip))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 365
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so there were 365 dog licenses that didn&amp;rsquo;t list appropriate zip codes. That&amp;rsquo;s alright, that&amp;rsquo;s less than 1% of our dataset. Let&amp;rsquo;s move forward.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It looks like several of the zipcodes listed are &amp;ldquo;industrial&amp;rdquo; zip codes. We&amp;rsquo;ll replace the zip code with the residential zip code that each industrial one falls within.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-26-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like the highest populations of licensed dogs are found in zipcodes 98115, 98103, and 98117. That corresponds roughly to Northeast Seattle, the area between Fremont and Greenwood, and the Ballard to Crown Hill area. It is certainly possible that the high dog populations in those areas could be correlated with the human population in the same areas. Let&amp;rsquo;s see how many licensed dogs there are per person in these areas.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Human Population Data Obtained &lt;a href=&#34;http://zipatlas.com/us/wa/seattle/zip-code-comparison/population-density.htm&#34;&gt;Here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;human_pop &amp;lt;- read.csv(&amp;quot;Human_Pop.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)

# Make a copy of our dataset (dog populations by zipcode)
pop_zip_2 &amp;lt;- pop_zip

# Match human populations from new dataset to zipcodes from
# dog population dataset
pop_zip_2$h_pop &amp;lt;- human_pop[match(pop_zip_2$region, human_pop$Zip), 
    &amp;quot;Population&amp;quot;]
pop_zip_2$h_pop &amp;lt;- gsub(&amp;quot;,&amp;quot;, &amp;quot;&amp;quot;, pop_zip_2$h_pop)
pop_zip_2$h_pop &amp;lt;- as.numeric(pop_zip_2$h_pop)


# Create new factor: dog_human (i.e. ratio of dogs to humans)
pop_zip_2 &amp;lt;- pop_zip_2 %&amp;gt;% filter(!is.na(h_pop)) %&amp;gt;% filter(h_pop &amp;gt; 
    10) %&amp;gt;% mutate(dog_human = value/h_pop) %&amp;gt;% select(1, 4)

# Change variable names for choroplethrZip
pop_zip_2 &amp;lt;- rename(pop_zip_2, value = dog_human)

# Plot
zip_choropleth(pop_zip_2, zip_zoom = (pop_zip_2$region), legend = &amp;quot;Dog:Human Ratio&amp;quot;, 
    reference_map = TRUE, num_colors = 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-27-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Generally speaking, central Seattle has a higher &amp;ldquo;Licensed Dogs : People&amp;rdquo; Ratio than the neighborhoods along the north and south edges. The highest proportion is found in zipcode 98117 or the Ballard to Crown Hill area with roughly 1 licensed dog for every 10 people. That is a residential area with lots of homes and fewer apartment buildings than the downtown-area.&lt;/p&gt;

&lt;p&gt;I wonder if there are more large dogs in those house-filled areas and small dogs in apartment-laden areas. Let&amp;rsquo;s map dog populations by their size.&lt;/p&gt;

&lt;p&gt;These figures will be proportions of small, medium, large and giant dogs in proportion to the number of dogs in each zipcode.&lt;/p&gt;

&lt;h3 id=&#34;dog-populations-by-size&#34;&gt;Dog Populations by Size&lt;/h3&gt;

&lt;h4 id=&#34;small&#34;&gt;Small&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-28-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;medium&#34;&gt;Medium&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-29-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;large&#34;&gt;Large&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-30-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;giant&#34;&gt;Giant&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-31-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;caveats-of-dog-size-by-zipcode&#34;&gt;Caveats of Dog Size by Zipcode&lt;/h3&gt;

&lt;p&gt;Wow! Looks like the largest proportion of small dogs is quite concentrated to zipcodes 98134 (Industrial District) and 98101 (Downtown Seattle, near Pike Place Market). These zip codes do have relatively small total dog populations though, totalling at only 38 and 487 dogs, respectively.&lt;/p&gt;

&lt;p&gt;Medium, large and giant sized dogs have a generally more consistent proportional distribution throughout the city. Both medium and large dogs have a higher than average proportion in zip code 98155, but again, this area boasts a small overall dog population (17 dogs total).&lt;/p&gt;

&lt;h3 id=&#34;dog-names&#34;&gt;Dog Names&lt;/h3&gt;

&lt;p&gt;Just for fun, let&amp;rsquo;s take a look at the most popular dog names in Seattle. Word cloud, anyone?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a corpus
names &amp;lt;- Corpus(VectorSource(dogs_5$Name))

# Convert to plain text document
names &amp;lt;- tm_map(names, PlainTextDocument)

# Remove numbers and punctuation, just in case
names &amp;lt;- tm_map(names, removeNumbers)
names &amp;lt;- tm_map(names, removePunctuation)

# Make all names lowercase
names &amp;lt;- tm_map(names, content_transformer(tolower))


# Generate the wordcloud
wordcloud(names, scale = c(5, 0.2), max.words = 150, random.order = FALSE, 
    rot.per = 0.35, use.r.layout = TRUE, colors = brewer.pal(6, 
        &amp;quot;Greens&amp;quot;)[c(4, 5, 6, 7, 8, 9)])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-32-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Oops! Looks like a few of those are probably not real names. We&amp;rsquo;ll go ahead and remove &amp;ldquo;dog&amp;rdquo;, &amp;ldquo;null&amp;rdquo;, &amp;ldquo;altered&amp;rdquo;, &amp;ldquo;female&amp;rdquo;, &amp;ldquo;male&amp;rdquo;, &amp;ldquo;labrador&amp;rdquo;, &amp;ldquo;retriever&amp;rdquo;, &amp;ldquo;year&amp;rdquo;, and &amp;ldquo;seattle&amp;rdquo; from the wordcloud.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Remove non-names
names_2 &amp;lt;- tm_map(names, removeWords, c(&amp;quot;dog&amp;quot;, &amp;quot;null&amp;quot;, &amp;quot;seattle&amp;quot;, 
    &amp;quot;altered&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;male&amp;quot;, &amp;quot;labrador&amp;quot;, &amp;quot;retriever&amp;quot;, &amp;quot;year&amp;quot;))

# Generate the wordcloud
wordcloud(names_2, scale = c(5, 0.2), max.words = 150, random.order = FALSE, 
    rot.per = 0.25, use.r.layout = TRUE, colors = brewer.pal(6, 
        &amp;quot;Greens&amp;quot;)[c(4, 5, 6, 7, 8, 9)])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-33-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Lucy looks like the clear winner here!&lt;/p&gt;

&lt;p&gt;Looks like some other well-known dog names (like Buddy) are pretty common in Seattle. How about &amp;ldquo;Rover&amp;rdquo;?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs_5 %&amp;gt;% filter(Name == &amp;quot;Rover&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##            License.Type.Sold Gender          Primary.Breed Primary.Color
## 1         Dog Altered 1 year   Male        German Shepherd          Rust
## 2         Dog Altered 1 year   Male     Labrador Retriever       Chocola
## 3         Dog Altered 2 year   Male                Maltese           Red
## 4         Dog Altered 2 year   Male     Labrador Retriever         Black
## 5         Dog Altered 2 year   Male  Australian Cattle Dog         Black
## 6 Dog Unaltered SR/HC 2 year   Male American Water Spaniel         Liver
##    Name Zip.C Male_Avg Female_Avg weight size_class   zip
## 1 Rover 98112     85.0       85.0   85.0      Large 98112
## 2 Rover 98103     72.5       62.5   72.5      Large 98103
## 3 Rover 98103      5.5        5.5    5.5      Small 98103
## 4 Rover 98122     72.5       62.5   72.5      Large 98122
## 5 Rover 98125     40.0       40.0   40.0     Medium 98125
## 6 Rover 98117     37.5       32.5   37.5     Medium 98117
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are 6 licensed dogs in Seattle named Rover!&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Dogs are basically everywhere in Seattle, but are most highly concentrated closer to the center of the city rather than on bordering neighborhoods.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Regardless of apartment-living, Seattle-ites are big fans of big dogs throughout the city.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The highest dog to human ratio is found in the Ballard to Crown Hill area, with nearly 1 dog per 10 people.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Generally, Seattle would be a great place to be a dog sitter or walker. To increase the likelihood of finding customers, I&amp;rsquo;d suggest being open to walking or pet-sitting large dogs where possible.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For a company like Rover.com which aims to connect dog-parents to dog sitters and walkers, I&amp;rsquo;d recommend providing this type of city-wide breakdown to potential sitters. I&amp;rsquo;d also suggest reaching out to large-dog owners to investigate their interest in becoming a sitter of other large dogs.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Without both sitter and user data from Rover.com, I am unable to make recommendations regarding the best neighborhood to become a dog sitter.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bicycle Sharing in Seattle</title>
      <link>/projects/Bicycle_Sharing_2/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/projects/Bicycle_Sharing_2/</guid>
      <description>&lt;p&gt;Data exploration, mapping, and data visualizations in RMarkdown.
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#importing-data&#34;&gt;Importing Data&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data-structures-and-variables&#34;&gt;Data Structures and Variables&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-visualizations&#34;&gt;Data Visualizations&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#exploring-the-stations-dataset&#34;&gt;Exploring the Stations Dataset&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#station-installations&#34;&gt;Station Installations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#current-station-size&#34;&gt;Current Station Size&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exploring-the-trips-dataset&#34;&gt;Exploring the Trips Dataset&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#plotting-trips-per-month-by-season&#34;&gt;Plotting Trips Per Month (By Season)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#average-trip-duration&#34;&gt;Average Trip Duration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#number-of-trips-by-day-of-week&#34;&gt;Number of Trips by Day of Week&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#number-of-trips-by-time-of-day&#34;&gt;Number of Trips by Time of Day&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#number-of-trips-by-member-type&#34;&gt;Number of Trips by Member Type&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trip-duration-by-member-type&#34;&gt;Trip Duration by Member Type&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#member-demographics&#34;&gt;Member Demographics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trip-routes&#34;&gt;Trip Routes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#station-by-trip-departure-and-arrival&#34;&gt;Station by Trip Departure and arrival&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#station-usage&#34;&gt;Station Usage&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exploring-the-weather-dataset&#34;&gt;Exploring the Weather Dataset&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#temperature&#34;&gt;Temperature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#events&#34;&gt;Events&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#combining-weather-and-trip-datasets&#34;&gt;Combining Weather and Trip Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mean-temperature-vs.-number-of-trips&#34;&gt;Mean Temperature vs. Number of Trips&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#precipitation-vs.-number-of-trips&#34;&gt;Precipitation vs. Number of Trips&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#suggestions-for-pronto&#34;&gt;Suggestions for Pronto!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is an exploration of bicycle-sharing data in the city of Seattle, WA (USA) from October 2014 - August 2016. I hope to eventually combine this data with other forms of ride-sharing and transportation in the city, but this will be the first step.&lt;/p&gt;

&lt;p&gt;Time to get started!&lt;/p&gt;

&lt;h3 id=&#34;loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# For data manipulation and tidying
library(dplyr)
library(lubridate)
library(tidyr)

# For mapping
library(ggmap)
library(mapproj)

# For data visualizations
library(ggplot2)

# For modeling and machine learning
library(caret)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;importing-data&#34;&gt;Importing Data&lt;/h3&gt;

&lt;p&gt;All of the data can be downloaded from the bicycle-sharing service &lt;a href=&#34;https://www.prontocycleshare.com/data&#34;&gt;&amp;ldquo;Pronto!&amp;rdquo;&amp;rsquo;s website&lt;/a&gt; or from &lt;a href=&#34;https://www.kaggle.com/pronto/cycle-share-dataset&#34;&gt;Kaggle&lt;/a&gt;. This project contains 3 data sets and I&amp;rsquo;ll import and inspect each data file independently.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;station &amp;lt;- read.csv(file = &amp;quot;2016_station_data.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = FALSE)

trip &amp;lt;- read.csv(file = &amp;quot;2016_trip_data.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = FALSE)

weather &amp;lt;- read.csv(file = &amp;quot;2016_weather_data.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, let&amp;rsquo;s take a look at each of these data files.&lt;/p&gt;

&lt;h4 id=&#34;data-structures-and-variables&#34;&gt;Data Structures and Variables&lt;/h4&gt;

&lt;h5 id=&#34;station&#34;&gt;Station&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 58
## Variables: 9
## $ station_id        &amp;lt;chr&amp;gt; &amp;quot;BT-01&amp;quot;, &amp;quot;BT-03&amp;quot;, &amp;quot;BT-04&amp;quot;, &amp;quot;BT-05&amp;quot;, &amp;quot;CBD-03&amp;quot;...
## $ name              &amp;lt;chr&amp;gt; &amp;quot;3rd Ave &amp;amp; Broad St&amp;quot;, &amp;quot;2nd Ave &amp;amp; Vine St&amp;quot;, &amp;quot;...
## $ lat               &amp;lt;dbl&amp;gt; 47.61842, 47.61583, 47.61609, 47.61311, 47.6...
## $ long              &amp;lt;dbl&amp;gt; -122.3510, -122.3486, -122.3411, -122.3442, ...
## $ install_date      &amp;lt;chr&amp;gt; &amp;quot;10/13/2014&amp;quot;, &amp;quot;10/13/2014&amp;quot;, &amp;quot;10/13/2014&amp;quot;, &amp;quot;1...
## $ install_dockcount &amp;lt;int&amp;gt; 18, 16, 16, 14, 20, 18, 20, 20, 20, 18, 16, ...
## $ modification_date &amp;lt;chr&amp;gt; &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;11/9/2015&amp;quot;, &amp;quot;&amp;quot;,...
## $ current_dockcount &amp;lt;int&amp;gt; 18, 16, 16, 14, 20, 18, 20, 18, 20, 18, 0, 1...
## $ decommission_date &amp;lt;chr&amp;gt; &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;8/9...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like this dataset is dealing with 9 variables:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Station ID&lt;/strong&gt; : The individual ID number for a bike station&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Name&lt;/strong&gt; : The name of that station ID, also appears to be the rough location of the station&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Latitude&lt;/strong&gt; : The latitude of the station&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Longitude&lt;/strong&gt; : The longitude of the station&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install Date&lt;/strong&gt; : When that particular station was installed (in MM/DD/YYYY format)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install Dock Count&lt;/strong&gt; : Number of docks (bike positions) available at each station on installation day&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modification Date&lt;/strong&gt; : When a particular station was modified (in MM/DD/YYYY format)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Current Dock Count&lt;/strong&gt; : Number of docks (bike positions) available at each station on August 31, 2016&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decommission Date&lt;/strong&gt; : The date that a particular station was put out of service (in MM/DD/YYYY format)&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;trip&#34;&gt;Trip&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 236,065
## Variables: 12
## $ trip_id           &amp;lt;int&amp;gt; 431, 432, 433, 434, 435, 436, 437, 438, 439,...
## $ starttime         &amp;lt;chr&amp;gt; &amp;quot;10/13/2014 10:31&amp;quot;, &amp;quot;10/13/2014 10:32&amp;quot;, &amp;quot;10/...
## $ stoptime          &amp;lt;chr&amp;gt; &amp;quot;10/13/2014 10:48&amp;quot;, &amp;quot;10/13/2014 10:48&amp;quot;, &amp;quot;10/...
## $ bikeid            &amp;lt;chr&amp;gt; &amp;quot;SEA00298&amp;quot;, &amp;quot;SEA00195&amp;quot;, &amp;quot;SEA00486&amp;quot;, &amp;quot;SEA0033...
## $ tripduration      &amp;lt;dbl&amp;gt; 985.935, 926.375, 883.831, 865.937, 923.923,...
## $ from_station_name &amp;lt;chr&amp;gt; &amp;quot;2nd Ave &amp;amp; Spring St&amp;quot;, &amp;quot;2nd Ave &amp;amp; Spring St&amp;quot;...
## $ to_station_name   &amp;lt;chr&amp;gt; &amp;quot;Occidental Park / Occidental Ave S &amp;amp; S Wash...
## $ from_station_id   &amp;lt;chr&amp;gt; &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD...
## $ to_station_id     &amp;lt;chr&amp;gt; &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;,...
## $ usertype          &amp;lt;chr&amp;gt; &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Mem...
## $ gender            &amp;lt;chr&amp;gt; &amp;quot;Male&amp;quot;, &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Male&amp;quot;, ...
## $ birthyear         &amp;lt;int&amp;gt; 1960, 1970, 1988, 1977, 1971, 1974, 1978, 19...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This dataset appears to contain 12 variables:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Trip ID&lt;/strong&gt; : An identification number assigned to each trip (from one bike station to another)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start Time&lt;/strong&gt; : The time and date that a bike was borrowed from a station (in MM/DD/YYYY HH:MM format)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stop Time&lt;/strong&gt; : The time and date that a bike was returned to a station (in MM/DD/YYYY HH:MM format)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bike ID&lt;/strong&gt; : The identification number for a specific bike&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Trip Duration&lt;/strong&gt; : Time of trip (measured in seconds)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;From Station Name&lt;/strong&gt; : The name of the station where the bike was borrowed from&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;To Station Name&lt;/strong&gt; : The name of the station where the bike was returned to&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;From Station ID&lt;/strong&gt; : The ID number of the station where the bike was borrowed from&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;To Station ID&lt;/strong&gt; : The ID number of the station where the bike was returned to&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User Type&lt;/strong&gt; : Indicates whether the user was a &amp;ldquo;Member&amp;rdquo; (i.e., someone with a monthly or annual membership to Pronto!) or a &amp;ldquo;Short-Term Pass Holder&amp;rdquo; (i.e., someone who purchased a 24 hour or 3 day pass)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gender&lt;/strong&gt; : The gender of the rider (if known)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Birth Year&lt;/strong&gt; : The year that the rider was born&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;weather&#34;&gt;Weather&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 689
## Variables: 21
## $ Date                       &amp;lt;chr&amp;gt; &amp;quot;10/13/2014&amp;quot;, &amp;quot;10/14/2014&amp;quot;, &amp;quot;10/15/...
## $ Max_Temperature_F          &amp;lt;int&amp;gt; 71, 63, 62, 71, 64, 68, 73, 66, 64,...
## $ Mean_Temperature_F         &amp;lt;int&amp;gt; 62, 59, 58, 61, 60, 64, 64, 60, 58,...
## $ Min_TemperatureF           &amp;lt;int&amp;gt; 54, 55, 54, 52, 57, 59, 55, 55, 55,...
## $ Max_Dew_Point_F            &amp;lt;int&amp;gt; 55, 52, 53, 49, 55, 59, 57, 57, 52,...
## $ MeanDew_Point_F            &amp;lt;int&amp;gt; 51, 51, 50, 46, 51, 57, 55, 54, 49,...
## $ Min_Dewpoint_F             &amp;lt;int&amp;gt; 46, 50, 46, 42, 41, 55, 53, 50, 46,...
## $ Max_Humidity               &amp;lt;int&amp;gt; 87, 88, 87, 83, 87, 90, 94, 90, 87,...
## $ Mean_Humidity              &amp;lt;int&amp;gt; 68, 78, 77, 61, 72, 83, 74, 78, 70,...
## $ Min_Humidity               &amp;lt;int&amp;gt; 46, 63, 67, 36, 46, 68, 52, 67, 58,...
## $ Max_Sea_Level_Pressure_In  &amp;lt;dbl&amp;gt; 30.03, 29.84, 29.98, 30.03, 29.83, ...
## $ Mean_Sea_Level_Pressure_In &amp;lt;dbl&amp;gt; 29.79, 29.75, 29.71, 29.95, 29.78, ...
## $ Min_Sea_Level_Pressure_In  &amp;lt;dbl&amp;gt; 29.65, 29.54, 29.51, 29.81, 29.73, ...
## $ Max_Visibility_Miles       &amp;lt;int&amp;gt; 10, 10, 10, 10, 10, 10, 10, 10, 10,...
## $ Mean_Visibility_Miles      &amp;lt;int&amp;gt; 10, 9, 9, 10, 10, 8, 10, 10, 10, 6,...
## $ Min_Visibility_Miles       &amp;lt;int&amp;gt; 4, 3, 3, 10, 6, 2, 6, 5, 6, 2, 10, ...
## $ Max_Wind_Speed_MPH         &amp;lt;int&amp;gt; 13, 10, 18, 9, 8, 10, 10, 12, 15, 1...
## $ Mean_Wind_Speed_MPH        &amp;lt;int&amp;gt; 4, 5, 7, 4, 3, 4, 3, 5, 8, 8, 9, 4,...
## $ Max_Gust_Speed_MPH         &amp;lt;chr&amp;gt; &amp;quot;21&amp;quot;, &amp;quot;17&amp;quot;, &amp;quot;25&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;1...
## $ Precipitation_In           &amp;lt;dbl&amp;gt; 0.00, 0.11, 0.45, 0.00, 0.14, 0.31,...
## $ Events                     &amp;lt;chr&amp;gt; &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Ra...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This dataset represents quite a bit of weather data in 21 variables.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Date&lt;/strong&gt; : The date in MM/DD/YYYY format&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Temperature F&lt;/strong&gt; : The maximum temperature that day (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Temperature F&lt;/strong&gt; : The average temperature that day (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Temperature F&lt;/strong&gt; : The minimum temperature that day (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Dew Point F&lt;/strong&gt; : The maximum dew point (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Dew Point F&lt;/strong&gt; : The average dew point (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Dew Point F&lt;/strong&gt; : The minimum dew point (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Humidity&lt;/strong&gt; : The maximum humidity (in %)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Humidity&lt;/strong&gt; : The average humidity (in %)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Humidity&lt;/strong&gt; : The minimum humidity (in %)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maximum Sea Level Pressure&lt;/strong&gt; : The maximum atmospheric pressure at sea level (in inches of mercury)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Sea Level Pressure&lt;/strong&gt; : The average atmospheric pressure at sea level (in inches of mercury)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Sea Level Pressure&lt;/strong&gt; : The minimum atmospheric pressure at sea level (in inches of mercury)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Visibility Miles&lt;/strong&gt; : The maximum visibility (in miles)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Visibility Miles&lt;/strong&gt; : The average visibility (in miles)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Visibility Miles&lt;/strong&gt; : The minimum visibility (in miles)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Wind Speed MPH&lt;/strong&gt; : The maximum sustained wind speed (in miles per hour)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Wind Speed MPH&lt;/strong&gt; : The average sustained wind speed (in miles per hour)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Gust Speed MPH&lt;/strong&gt; : The maximum gust wind speed (in miles per hour)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Precipitation&lt;/strong&gt; : The amount of precipitation (measured in inches)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Events&lt;/strong&gt; : Weather events that occurred that day (e.g., rain, fog, snow, thunderstorm etc.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;data-visualizations&#34;&gt;Data Visualizations&lt;/h2&gt;

&lt;h3 id=&#34;exploring-the-stations-dataset&#34;&gt;Exploring the Stations Dataset&lt;/h3&gt;

&lt;p&gt;Since the &amp;ldquo;Stations&amp;rdquo; dataset was the first one I imported, let&amp;rsquo;s start with a little exploration there. First of all, how many unique stations are we dealing with?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;station %&amp;gt;% summarise(n_distinct(station_id))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   n_distinct(station_id)
## 1                     58
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wow! 58 different stations! Let&amp;rsquo;s take a quick peek at where they are located.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;station_locs &amp;lt;- station %&amp;gt;% group_by(station_id) %&amp;gt;% select(1:4, 
    -2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Load the correct map
mymap &amp;lt;- get_map(location = &amp;quot;Seattle&amp;quot;, maptype = &amp;quot;roadmap&amp;quot;, zoom = 12)

# Plot a single point for each Station ID
ggmap(mymap) + geom_point(aes(x = long, y = lat), data = station_locs, 
    alpha = 0.7, color = &amp;quot;darkred&amp;quot;, size = 2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-8-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So it looks like all of the stations are located near the Lower Queen Anne, Belltown, International District, Capitol Hill and University of Washington areas. Let&amp;rsquo;s take a more zoomed-in look.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-9-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Great! So the locations are pretty well clustered. I wonder what order they were added in.&lt;/p&gt;

&lt;h4 id=&#34;station-installations&#34;&gt;Station Installations&lt;/h4&gt;

&lt;p&gt;First, let&amp;rsquo;s convert those character-string date objects to actual dates using the &lt;code&gt;lubridate&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;station$install_date &amp;lt;- mdy(station$install_date)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# How many times were new stations installed?
station %&amp;gt;% summarise(n_distinct(install_date))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   n_distinct(install_date)
## 1                        9
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# How many stations were installed on each date?
station %&amp;gt;% group_by(install_date) %&amp;gt;% summarise(count = n()) %&amp;gt;% 
    arrange(install_date)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 9 × 2
##   install_date count
##         &amp;lt;date&amp;gt; &amp;lt;int&amp;gt;
## 1   2014-10-13    50
## 2   2015-05-22     1
## 3   2015-06-12     1
## 4   2015-07-27     1
## 5   2015-09-15     1
## 6   2015-10-29     1
## 7   2016-03-18     1
## 8   2016-07-03     1
## 9   2016-08-09     1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like the vast majority (86%) of the stations were added on opening day. Let&amp;rsquo;s see where those original ones were and where the rest were added.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-12-1.png&#34; alt=&#34;&#34; /&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-12-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So they added more stations throughout the district that they serve, instead of adding several new stations to a single neighborhood all at once. Good to know.&lt;/p&gt;

&lt;p&gt;Now, I wonder how many bikes can be parked at each station (as of August 31,2016)?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-13-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Well that&amp;rsquo;s weird, some of the stations have a dock count of 0. I&amp;rsquo;m assuming they didn&amp;rsquo;t start that way. Let&amp;rsquo;s calculate the change in dock count from station installation to August 31, 2016 and plot it on a map.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dock_change &amp;lt;- station %&amp;gt;% group_by(station_id) %&amp;gt;% select(station_id, 
    long, lat, ends_with(&amp;quot;dockcount&amp;quot;)) %&amp;gt;% mutate(dock_change = current_dockcount - 
    install_dockcount)
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;change-in-number-of-bike-docks-per-station&#34;&gt;Change in Number of Bike Docks Per Station&lt;/h5&gt;

&lt;p&gt;Any stations with no change in number of docks are not shown here. &lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-15-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Looks like quite a few stations took away bike docks and none gained any. Perhaps those stations weren&amp;rsquo;t being used very frequently. We&amp;rsquo;ll have to look at that a bit later.&lt;/p&gt;

&lt;h4 id=&#34;current-station-size&#34;&gt;Current Station Size&lt;/h4&gt;

&lt;p&gt;I&amp;rsquo;m going to take one quick look at the current size of each station before moving on to the next dataset. &lt;em&gt;Note: I did not include any stations that were closed as of August 31, 2016 in this map&lt;/em&gt; &lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-16-1.png&#34;  class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So it looks like the biggest stations tend to be on the outskirts of the rest. Where there are several stations in close proximity, there tend to be fewer bike docks at each station. That makes sense, logically speaking. If you go to a station and there is no bike to rent, you can easily go to another nearby, assuming there is another nearby. In areas where the stations are more secluded, it&amp;rsquo;s more important that there be bikes and open spaces readily available for users.&lt;/p&gt;

&lt;p&gt;Alright, I&amp;rsquo;m feeling good about exploring this dataset. Time to check out the trip dataset!&lt;/p&gt;

&lt;h3 id=&#34;exploring-the-trips-dataset&#34;&gt;Exploring the Trips Dataset&lt;/h3&gt;

&lt;p&gt;It&amp;rsquo;s been a while since we&amp;rsquo;ve looked at the trip dataset, so let&amp;rsquo;s take another peek at it here.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 236,065
## Variables: 12
## $ trip_id           &amp;lt;int&amp;gt; 431, 432, 433, 434, 435, 436, 437, 438, 439,...
## $ starttime         &amp;lt;chr&amp;gt; &amp;quot;10/13/2014 10:31&amp;quot;, &amp;quot;10/13/2014 10:32&amp;quot;, &amp;quot;10/...
## $ stoptime          &amp;lt;chr&amp;gt; &amp;quot;10/13/2014 10:48&amp;quot;, &amp;quot;10/13/2014 10:48&amp;quot;, &amp;quot;10/...
## $ bikeid            &amp;lt;chr&amp;gt; &amp;quot;SEA00298&amp;quot;, &amp;quot;SEA00195&amp;quot;, &amp;quot;SEA00486&amp;quot;, &amp;quot;SEA0033...
## $ tripduration      &amp;lt;dbl&amp;gt; 985.935, 926.375, 883.831, 865.937, 923.923,...
## $ from_station_name &amp;lt;chr&amp;gt; &amp;quot;2nd Ave &amp;amp; Spring St&amp;quot;, &amp;quot;2nd Ave &amp;amp; Spring St&amp;quot;...
## $ to_station_name   &amp;lt;chr&amp;gt; &amp;quot;Occidental Park / Occidental Ave S &amp;amp; S Wash...
## $ from_station_id   &amp;lt;chr&amp;gt; &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD...
## $ to_station_id     &amp;lt;chr&amp;gt; &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;,...
## $ usertype          &amp;lt;chr&amp;gt; &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Mem...
## $ gender            &amp;lt;chr&amp;gt; &amp;quot;Male&amp;quot;, &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Male&amp;quot;, ...
## $ birthyear         &amp;lt;int&amp;gt; 1960, 1970, 1988, 1977, 1971, 1974, 1978, 19...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great, so there are quite a few things that we can potentially look at using this dataset by itself. Let&amp;rsquo;s start with the number of trips per day since Pronto! began opening bike stations. To do that, we need to recode our start date/times as POSIXct objects. We&amp;rsquo;ll use the &lt;code&gt;lubridate&lt;/code&gt; package for this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Make the start and stop dates into POSIXct objects
trip_2 &amp;lt;- trip %&amp;gt;% mutate(start_dt = mdy_hm(starttime), stop_dt = mdy_hm(stoptime))

# Recode the dates
trip_2 &amp;lt;- trip_2 %&amp;gt;% mutate(start_date = paste(month(start_dt), 
    day(start_dt), year(start_dt), sep = &amp;quot;/&amp;quot;))
trip_2$start_date &amp;lt;- mdy(trip_2$start_date)

trip_2 &amp;lt;- trip_2 %&amp;gt;% mutate(stop_date = paste(month(stop_dt), 
    day(stop_dt), year(stop_dt), sep = &amp;quot;/&amp;quot;))
trip_2$stop_date &amp;lt;- mdy(trip_2$stop_date)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Time to visualize the number of rides per day.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-19-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hmm, grouping by day is a little noisy. Perhaps we should try by month?&lt;/p&gt;

&lt;h4 id=&#34;plotting-trips-per-month-by-season&#34;&gt;Plotting Trips Per Month (By Season)&lt;/h4&gt;

&lt;p&gt;First, we need to create a &amp;ldquo;Year-Month&amp;rdquo; variable&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;start_date_ym &amp;lt;- trip_2 %&amp;gt;% mutate(ym = paste(year(start_date), 
    month(start_date), sep = &amp;quot;/&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now plot. I think I&amp;rsquo;ll plot this by month but color it by season (where December, January, and February are &amp;ldquo;winter&amp;rdquo;, March, April, and May are &amp;ldquo;spring&amp;rdquo;, June, July, August are &amp;ldquo;summer&amp;rdquo;, and September, October, November are &amp;ldquo;autumn&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-21-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Well that intuitively makes sense. The number of trips taken per month increases in the spring, reaches a maximum in the summer, declines through the fall, remains fairly stable in the winter and then repeats.&lt;/p&gt;

&lt;h4 id=&#34;average-trip-duration&#34;&gt;Average Trip Duration&lt;/h4&gt;

&lt;p&gt;Great! I wonder how the average trip duration fluctuates over this time period.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Convert Trip Duration from Seconds to Minutes
Trip_Duration_Month &amp;lt;- start_date_ym %&amp;gt;% mutate(trip_duration_min = tripduration/60) %&amp;gt;% 
    group_by(ym) %&amp;gt;% select(ym, trip_duration_min) %&amp;gt;% summarise(Avg = mean(trip_duration_min), 
    sd = sd(trip_duration_min)) %&amp;gt;% mutate(se = sd/sqrt(n()))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now to plot the average trip duration (in minutes) (plus or minus standard error), with colors indicating season.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-23-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s surprisingly not a huge range in trip durations here.&lt;/p&gt;

&lt;p&gt;The little bit of variation here makes logical sense. Longer trips were being taken in the spring and summer months rather than the fall and winter. It&amp;rsquo;s also notable that the spring and summer of 2016 may have shown fewer trips than the previous year, show a slight increase in average trip length.&lt;/p&gt;

&lt;h4 id=&#34;number-of-trips-by-day-of-week&#34;&gt;Number of Trips by Day of Week&lt;/h4&gt;

&lt;p&gt;I wonder if people are using this service to commute to/from work. Let&amp;rsquo;s look at the number of trips by day of the week.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s create a Day of the Week variable.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;trip_2$wd &amp;lt;- wday(trip_2$start_date, label = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now to plot the total number of trips by day of the week.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-25-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Ok, so there are definitely more trips during the week than on the weekends. I wonder if this varies by season too.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-26-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So it looks like usage is relatively consistent across seasons, at least as far as the number of trips are concerned.&lt;/p&gt;

&lt;h4 id=&#34;number-of-trips-by-time-of-day&#34;&gt;Number of Trips by Time of Day&lt;/h4&gt;

&lt;p&gt;How about time of day? Are people using these around commuting times during the week and later on weekends?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-27-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow, looks like regardless of the season, people are commuting to/from work using this service (there&amp;rsquo;s a spike between 8 and 10 AM and another between 4 and 7 PM Monday through Friday). But the weekends seem to be popular between 10 AM and 10 PM.&lt;/p&gt;

&lt;h4 id=&#34;number-of-trips-by-member-type&#34;&gt;Number of Trips by Member Type&lt;/h4&gt;

&lt;p&gt;I wonder if different types of members (those who have a membership vs. those that bought a 24 hour or 3 day pass) vary in the number of trips they take.&lt;/p&gt;

&lt;p&gt;If I were to guess, I&amp;rsquo;d think the short-term passes would be ideal for tourists or people looking for a quick weekend trip, whereas members may be more likely to continue using the service year-round. Let&amp;rsquo;s check out my assumptions by plotting, once again colored by season.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-28-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Surprisingly (to me, at least), different types of users seem to follow similar patterns of usage. Spring and Summer are definitely the most popular times for anyone to ride a bike in the Seattle area.&lt;/p&gt;

&lt;h4 id=&#34;trip-duration-by-member-type&#34;&gt;Trip Duration by Member Type&lt;/h4&gt;

&lt;p&gt;While it may seem that the trip duration shouldn&amp;rsquo;t vary widely by member type, a quick look at &lt;a href=&#34;https://www.prontocycleshare.com/pricing&#34;&gt;Pronto!&amp;rsquo;s pricing structure&lt;/a&gt; may make you reconsider that assumption. You see, while you have to purchase either an annual membership ($85/year), a 24-Hour Pass ($8) or a 3-Day Pass ($16) there is still a cap on the duration of your trip. For members, any ride under 45 minutes is free, but any ride going over 45 minutes will incur a fee of $2 for every additional 30 minutes. For short-term users, any ride under 30 minutes is free, but going over that time limit would cost you an additional $2 for the first 30 minutes and $5 for each additional 30 minutes after that!&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if these time limits cause differing behaviors in our users.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-29-1.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Ok, so our members are pretty good about making sure that they return their bike before they incur extra charges, but the short-term pass holders frequently go over their time limit. I wonder how the cost of a trip varies for members and pass holders. Let&amp;rsquo;s try to calculate the cost of a trip.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;trip_cost &amp;lt;- trip_2 %&amp;gt;% mutate(cost = ifelse(usertype == &amp;quot;Member&amp;quot; &amp;amp; 
    tripduration_m &amp;lt;= 45, 0, ifelse(usertype == &amp;quot;Member&amp;quot; &amp;amp; tripduration_m &amp;gt; 
    45 &amp;amp; tripduration_m &amp;lt;= 75, 2, ifelse(usertype == &amp;quot;Member&amp;quot; &amp;amp; 
    tripduration_m &amp;gt; 75, (2 + 5 * ((tripduration_m - 75)/30)), 
    ifelse(usertype == &amp;quot;Short-Term Pass Holder&amp;quot; &amp;amp; tripduration_m &amp;lt;= 
        30, 0, ifelse(usertype == &amp;quot;Short-Term Pass Holder&amp;quot; &amp;amp; 
        tripduration_m &amp;gt; 30 &amp;amp; tripduration_m &amp;lt; 60, 2, ifelse(usertype == 
        &amp;quot;Short-Term Pass Holder&amp;quot; &amp;amp; tripduration_m &amp;gt; 60, (2 + 
        5 * ((tripduration_m - 60)/30)), &amp;quot;unknown&amp;quot;)))))))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That was a complicated nested if/else statement! Let&amp;rsquo;s see how much these folks are paying in additional fees!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-31-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like short-term pass holders (who are already paying a higher price per day of biking), are also paying lots of extra fees. This could be because they are unfamiliar with the pricing structure and don&amp;rsquo;t realize they need to return their bike to a station within 30 minutes without getting charged. It is also possible that short-term users may be tourists who don&amp;rsquo;t know their way around as easily, and thus can&amp;rsquo;t find their way to a station within the time limit.&lt;/p&gt;

&lt;h4 id=&#34;member-demographics&#34;&gt;Member Demographics&lt;/h4&gt;

&lt;p&gt;We only seem to have age and gender information about people who have an annual Pronto! membership, so we can at least take a look at what types of people use this service.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look first at age.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;trip_2$usertype &amp;lt;- as.factor(trip_2$usertype)
trip_age &amp;lt;- trip_2 %&amp;gt;% mutate(age = year(start_dt) - birthyear)

hist(trip_age$age, main = &amp;quot;Member Age&amp;quot;, xlab = &amp;quot;Number of Riders&amp;quot;, 
    col = &amp;quot;#56B4E9&amp;quot;, breaks = 25)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-32-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;My first instinct here is to say &amp;ldquo;Wow! There&amp;rsquo;s a lot of 20 and 30-somethings that use this service!&amp;rdquo; But this figure (and these data) may be a little misleading. You see, we don&amp;rsquo;t have any sort of Rider ID number, meaning we can&amp;rsquo;t take &amp;ldquo;individual activity level&amp;rdquo; into account. So we can&amp;rsquo;t tell if the tallest spike is because 5 very athletic 28-year-olds went on 4,000 trips each, or if 100 people went on 200 trips each, or if there were 20,000 28-year-olds who each only used the service once.&lt;/p&gt;

&lt;p&gt;The same problem would arise if we looked at gender, so I&amp;rsquo;m just going to move beyond demographics.&lt;/p&gt;

&lt;h4 id=&#34;trip-routes&#34;&gt;Trip Routes&lt;/h4&gt;

&lt;p&gt;I&amp;rsquo;m going to do my best to look at some potential routes that these users could have taken, given their start and stop locations and duration. All of these data will be analyzed using the &lt;code&gt;ggmap&lt;/code&gt; package and Google Maps API (&lt;a href=&#34;https://journal.r-project.org/archive/2013-1/kahle-wickham.pdf&#34;&gt;more info here&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;To start, I need to combine the coordinates of the station (from the &lt;code&gt;station&lt;/code&gt; dataset) with the data from the &lt;code&gt;trip&lt;/code&gt; dataset. Let&amp;rsquo;s get started.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a dataframe with only station ID, latitude, and
# longitude
station_coord &amp;lt;- station %&amp;gt;% select(station_id, lat, long)

# Trim our trip dataframe to only include start &amp;amp; stop
# dates/times, and station ID
trip_route &amp;lt;- trip_2 %&amp;gt;% select(trip_id, starts_with(&amp;quot;start_&amp;quot;), 
    starts_with(&amp;quot;stop_&amp;quot;), from_station_id, to_station_id, tripduration)

# Match by station ID
trip_route$start_lat &amp;lt;- station_coord[match(trip_route$from_station_id, 
    station_coord$station_id), &amp;quot;lat&amp;quot;]

trip_route$start_long &amp;lt;- station_coord[match(trip_route$from_station_id, 
    station_coord$station_id), &amp;quot;long&amp;quot;]

trip_route$stop_lat &amp;lt;- station_coord[match(trip_route$to_station_id, 
    station_coord$station_id), &amp;quot;lat&amp;quot;]

trip_route$stop_long &amp;lt;- station_coord[match(trip_route$to_station_id, 
    station_coord$station_id), &amp;quot;long&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Now to start looking at routes.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll start by looking at the possible routes of the very first trip.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-34-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Cool! So Google Maps API was able to give us two potential routes for this particular trip. We can make a best guess on which trip was taken by determining the trip duration.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Converting trip duration to minutes
trip_route$tripduration &amp;lt;- trip_route$tripduration/60

# Finding actual trip duration
trip_route[1, &amp;quot;tripduration&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 16.43225
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so the actual trip on October 13, 2014 took 16.4 minutes. Let&amp;rsquo;s see how long each of the hypothetical trips took.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;leg_1 %&amp;gt;% group_by(route) %&amp;gt;% summarise(duration = sum(minutes))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 2
##   route duration
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
## 1     A 4.950000
## 2     B 5.583333
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hmm, looks like Google estimates those trips should have only taken between 5 and 6 minutes. It is very possible that our user did not go directly from one station to the other. It&amp;rsquo;s also possible that he got stopped at a few red lights along his route.&lt;/p&gt;

&lt;p&gt;Perhaps this, being the first trip, was a demo of some sort. Let&amp;rsquo;s check out the last trip that was recorded and see if we still run into the same time disconnect.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-37-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt; Well this was certainly a longer ride than the first one we looked at!&lt;/p&gt;

&lt;p&gt;How long did this trip take?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;trip_route[nrow(trip_route), &amp;quot;tripduration&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 31.60052
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so how long did Google estimate it should take?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;leg_2 %&amp;gt;% group_by(route) %&amp;gt;% summarise(duration = sum(minutes))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 2
##   route duration
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
## 1     A  9.50000
## 2     B 12.13333
## 3     C 13.45000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once again, the trip took quite a bit longer than any of the routes shown here. It&amp;rsquo;s possible that estimating the routes taken by cyclists is not the best use of this dataset. So, what else is there to look at?&lt;/p&gt;

&lt;h4 id=&#34;station-by-trip-departure-and-arrival&#34;&gt;Station by Trip Departure and arrival&lt;/h4&gt;

&lt;p&gt;I suppose we can see which stations have the most trip departures and which have the most arrivals. Unless people are always making round-trip journeys, these are not likely to be equal.&lt;/p&gt;

&lt;h4 id=&#34;station-usage&#34;&gt;Station Usage&lt;/h4&gt;

&lt;h5 id=&#34;trip-departure&#34;&gt;Trip Departure&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-40-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Great, so it looks like the station that sends the highest number of bikes out and takes the highest number of bikes in is located at Pier 69 / Alaskan Way &amp;amp; Clay Street. Looks like this is pretty close to a few parks and several big tourist attractions.&lt;/p&gt;

&lt;p&gt;Also, if you flip between &amp;ldquo;Departures&amp;rdquo; and &amp;ldquo;Arrivals&amp;rdquo;, you&amp;rsquo;ll notice that quite a few bikes are picked up in the Capitol Hill area, but are returned down by the coast. If you&amp;rsquo;re unfamiliar with Seattle&amp;rsquo;s topography, Capitol Hill is aptly named because it&amp;rsquo;s situated on a very steep hill. It makes sense that people would borrow bikes to ride &lt;em&gt;down&lt;/em&gt; the hill, but not want to borrow a bike to go back &lt;em&gt;up&lt;/em&gt; the hill. Interesting!&lt;/p&gt;

&lt;h5 id=&#34;trip-arrival&#34;&gt;Trip Arrival&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-41-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Great, so it looks like the station that sends the highest number of bikes out and takes the highest number of bikes in is located at Pier 69 / Alaskan Way &amp;amp; Clay Street. Looks like this is pretty close to a few parks and several big tourist attractions.&lt;/p&gt;

&lt;p&gt;Also, if you flip between &amp;ldquo;Departures&amp;rdquo; and &amp;ldquo;Arrivals&amp;rdquo;, you&amp;rsquo;ll notice that quite a few bikes are picked up in the Capitol Hill area, but are returned down by the coast. If you&amp;rsquo;re unfamiliar with Seattle&amp;rsquo;s topography, Capitol Hill is aptly named because it&amp;rsquo;s situated on a very steep hill. It makes sense that people would borrow bikes to ride &lt;em&gt;down&lt;/em&gt; the hill, but not want to borrow a bike to go back &lt;em&gt;up&lt;/em&gt; the hill. Interesting!&lt;/p&gt;

&lt;h3 id=&#34;exploring-the-weather-dataset&#34;&gt;Exploring the Weather Dataset&lt;/h3&gt;

&lt;p&gt;Now that I&amp;rsquo;ve visualized all that I can think of in terms of the &amp;ldquo;trips&amp;rdquo; dataset, it&amp;rsquo;s time to take a brief look at the weather dataset.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s get a quick reminder of what we&amp;rsquo;re looking at here.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;glimpse(weather)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 689
## Variables: 21
## $ Date                       &amp;lt;chr&amp;gt; &amp;quot;10/13/2014&amp;quot;, &amp;quot;10/14/2014&amp;quot;, &amp;quot;10/15/...
## $ Max_Temperature_F          &amp;lt;int&amp;gt; 71, 63, 62, 71, 64, 68, 73, 66, 64,...
## $ Mean_Temperature_F         &amp;lt;int&amp;gt; 62, 59, 58, 61, 60, 64, 64, 60, 58,...
## $ Min_TemperatureF           &amp;lt;int&amp;gt; 54, 55, 54, 52, 57, 59, 55, 55, 55,...
## $ Max_Dew_Point_F            &amp;lt;int&amp;gt; 55, 52, 53, 49, 55, 59, 57, 57, 52,...
## $ MeanDew_Point_F            &amp;lt;int&amp;gt; 51, 51, 50, 46, 51, 57, 55, 54, 49,...
## $ Min_Dewpoint_F             &amp;lt;int&amp;gt; 46, 50, 46, 42, 41, 55, 53, 50, 46,...
## $ Max_Humidity               &amp;lt;int&amp;gt; 87, 88, 87, 83, 87, 90, 94, 90, 87,...
## $ Mean_Humidity              &amp;lt;int&amp;gt; 68, 78, 77, 61, 72, 83, 74, 78, 70,...
## $ Min_Humidity               &amp;lt;int&amp;gt; 46, 63, 67, 36, 46, 68, 52, 67, 58,...
## $ Max_Sea_Level_Pressure_In  &amp;lt;dbl&amp;gt; 30.03, 29.84, 29.98, 30.03, 29.83, ...
## $ Mean_Sea_Level_Pressure_In &amp;lt;dbl&amp;gt; 29.79, 29.75, 29.71, 29.95, 29.78, ...
## $ Min_Sea_Level_Pressure_In  &amp;lt;dbl&amp;gt; 29.65, 29.54, 29.51, 29.81, 29.73, ...
## $ Max_Visibility_Miles       &amp;lt;int&amp;gt; 10, 10, 10, 10, 10, 10, 10, 10, 10,...
## $ Mean_Visibility_Miles      &amp;lt;int&amp;gt; 10, 9, 9, 10, 10, 8, 10, 10, 10, 6,...
## $ Min_Visibility_Miles       &amp;lt;int&amp;gt; 4, 3, 3, 10, 6, 2, 6, 5, 6, 2, 10, ...
## $ Max_Wind_Speed_MPH         &amp;lt;int&amp;gt; 13, 10, 18, 9, 8, 10, 10, 12, 15, 1...
## $ Mean_Wind_Speed_MPH        &amp;lt;int&amp;gt; 4, 5, 7, 4, 3, 4, 3, 5, 8, 8, 9, 4,...
## $ Max_Gust_Speed_MPH         &amp;lt;chr&amp;gt; &amp;quot;21&amp;quot;, &amp;quot;17&amp;quot;, &amp;quot;25&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;1...
## $ Precipitation_In           &amp;lt;dbl&amp;gt; 0.00, 0.11, 0.45, 0.00, 0.14, 0.31,...
## $ Events                     &amp;lt;chr&amp;gt; &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Ra...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great, let&amp;rsquo;s change the Date variable to a POSIXct object, and make the &amp;ldquo;Events&amp;rdquo; variable factors.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Adjusting the Date Variable
weather$Date &amp;lt;- mdy(weather$Date)

# Adjusting the Events Variable
weather$Events &amp;lt;- as.factor(weather$Events)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great. Now how many weather events are there?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;levels(weather$Events)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;&amp;quot;                    &amp;quot;Fog&amp;quot;                 &amp;quot;Fog , Rain&amp;quot;         
##  [4] &amp;quot;Fog-Rain&amp;quot;            &amp;quot;Rain&amp;quot;                &amp;quot;Rain , Snow&amp;quot;        
##  [7] &amp;quot;Rain , Thunderstorm&amp;quot; &amp;quot;Rain-Snow&amp;quot;           &amp;quot;Rain-Thunderstorm&amp;quot;  
## [10] &amp;quot;Snow&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wow! So mostly combinations of rain&amp;hellip;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s combine a few of these things that seem to represent the same event.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather$Events &amp;lt;- gsub(&amp;quot;Fog , Rain|Fog-Rain&amp;quot;, &amp;quot;Fog-Rain&amp;quot;, weather$Events)
weather$Events &amp;lt;- gsub(&amp;quot;Rain , Snow|Rain-Snow&amp;quot;, &amp;quot;Rain-Snow&amp;quot;, 
    weather$Events)
weather$Events &amp;lt;- gsub(&amp;quot;Rain , Thunderstorm|Rain-Thunderstorm&amp;quot;, 
    &amp;quot;Rain-TS&amp;quot;, weather$Events)

weather$Events &amp;lt;- as.factor(weather$Events)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where else does this dataset need to be cleaned up? Let&amp;rsquo;s look for any missing values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(weather)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##       Date            Max_Temperature_F Mean_Temperature_F
##  Min.   :2014-10-13   Min.   :39.00     Min.   :33.00     
##  1st Qu.:2015-04-03   1st Qu.:55.00     1st Qu.:48.00     
##  Median :2015-09-22   Median :63.00     Median :56.00     
##  Mean   :2015-09-22   Mean   :64.03     Mean   :56.58     
##  3rd Qu.:2016-03-12   3rd Qu.:73.00     3rd Qu.:65.00     
##  Max.   :2016-08-31   Max.   :98.00     Max.   :83.00     
##                                         NA&#39;s   :1         
##  Min_TemperatureF Max_Dew_Point_F MeanDew_Point_F Min_Dewpoint_F 
##  Min.   :23.00    Min.   :10.00   Min.   : 4.00   Min.   : 1.00  
##  1st Qu.:43.00    1st Qu.:44.00   1st Qu.:41.00   1st Qu.:36.00  
##  Median :50.00    Median :50.00   Median :46.00   Median :42.00  
##  Mean   :49.45    Mean   :48.57   Mean   :45.02   Mean   :40.87  
##  3rd Qu.:57.00    3rd Qu.:54.00   3rd Qu.:51.00   3rd Qu.:47.00  
##  Max.   :70.00    Max.   :77.00   Max.   :59.00   Max.   :57.00  
##                                                                  
##   Max_Humidity    Mean_Humidity    Min_Humidity  
##  Min.   : 40.00   Min.   :24.00   Min.   :15.00  
##  1st Qu.: 78.00   1st Qu.:60.00   1st Qu.:38.00  
##  Median : 86.00   Median :70.00   Median :50.00  
##  Mean   : 84.54   Mean   :68.51   Mean   :49.97  
##  3rd Qu.: 90.00   3rd Qu.:79.00   3rd Qu.:63.00  
##  Max.   :100.00   Max.   :95.00   Max.   :87.00  
##                                                  
##  Max_Sea_Level_Pressure_In Mean_Sea_Level_Pressure_In
##  Min.   :29.47             Min.   :29.31             
##  1st Qu.:30.01             1st Qu.:29.93             
##  Median :30.12             Median :30.04             
##  Mean   :30.12             Mean   :30.03             
##  3rd Qu.:30.24             3rd Qu.:30.16             
##  Max.   :30.86             Max.   :30.81             
##                                                      
##  Min_Sea_Level_Pressure_In Max_Visibility_Miles Mean_Visibility_Miles
##  Min.   :29.14             Min.   : 3.00        Min.   : 1.00        
##  1st Qu.:29.84             1st Qu.:10.00        1st Qu.: 9.00        
##  Median :29.96             Median :10.00        Median :10.00        
##  Mean   :29.94             Mean   : 9.99        Mean   : 9.43        
##  3rd Qu.:30.08             3rd Qu.:10.00        3rd Qu.:10.00        
##  Max.   :30.75             Max.   :10.00        Max.   :10.00        
##                                                                      
##  Min_Visibility_Miles Max_Wind_Speed_MPH Mean_Wind_Speed_MPH
##  Min.   : 0.000       Min.   : 4.00      Min.   : 0.000     
##  1st Qu.: 4.000       1st Qu.: 8.00      1st Qu.: 3.000     
##  Median : 9.000       Median :10.00      Median : 4.000     
##  Mean   : 7.245       Mean   :11.09      Mean   : 4.631     
##  3rd Qu.:10.000       3rd Qu.:13.00      3rd Qu.: 6.000     
##  Max.   :10.000       Max.   :30.00      Max.   :23.000     
##                                                             
##  Max_Gust_Speed_MPH Precipitation_In       Events   
##  Length:689         Min.   :0.0000            :361  
##  Class :character   1st Qu.:0.0000   Fog      : 16  
##  Mode  :character   Median :0.0000   Fog-Rain : 13  
##                     Mean   :0.1051   Rain     :287  
##                     3rd Qu.:0.0900   Rain-Snow:  3  
##                     Max.   :2.2000   Rain-TS  :  7  
##                                      Snow     :  2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so we have one NA for &amp;ldquo;Mean_Temperature_F&amp;rdquo;, &amp;ldquo;Max_Gust_Speed_MPH&amp;rdquo; seems to be represented as a character vector because it has &amp;ldquo;-&amp;rdquo; representing NA values, and we have 361 unlabelled Events.&lt;/p&gt;

&lt;p&gt;Max Gust Speed should be the easiest one to fix, so we&amp;rsquo;ll start there.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather$Max_Gust_Speed_MPH &amp;lt;- gsub(&amp;quot;-&amp;quot;, 0, weather$Max_Gust_Speed_MPH)

weather$Max_Gust_Speed_MPH &amp;lt;- as.numeric(weather$Max_Gust_Speed_MPH)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! We changed any absent values for Maximum Gust Speed to 0 MPH and changed the variable type to a number. Uh oh, looks like there are still 185 NA values for Max Gust Speed. That&amp;rsquo;s a lot to try to replace. I would normally suggest generating a model that could try to predict those values based on other known values, but for now, we&amp;rsquo;ll just leave it alone.&lt;/p&gt;

&lt;p&gt;Since there is only one missing Mean Temperature, it seems the easiest way to fill in the hole is to look up what the average temperature was that day. &lt;em&gt;Note: I certainly would not recommend this if it were any more than one missing value&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather[which(is.na(weather$Mean_Temperature_F)), 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2016-02-14&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so we&amp;rsquo;re looking for the Mean Temperature on February 14, 2016 in the zipcode 98101 (according to dataset documentation). Looks like the mean temperature that day was 50 degrees F.&lt;/p&gt;

&lt;p&gt;Time to substitute in that value.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather[490, &amp;quot;Mean_Temperature_F&amp;quot;] &amp;lt;- &amp;quot;50&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect. Now what to do with the unlabelled &amp;ldquo;Event&amp;rdquo; categories. The dataset &amp;ldquo;ReadMe&amp;rdquo; file from Pronto! doesn&amp;rsquo;t include any information about this weather dataset. The only thing I can think to do is refer to the Event as &amp;ldquo;Other&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather$Events &amp;lt;- gsub(&amp;quot;^$&amp;quot;, &amp;quot;Other&amp;quot;, weather$Events)
weather$Events &amp;lt;- as.factor(weather$Events)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, we&amp;rsquo;re in good shape. Now to do a few quick visualizations.&lt;/p&gt;

&lt;h4 id=&#34;temperature&#34;&gt;Temperature&lt;/h4&gt;

&lt;h5 id=&#34;minimum&#34;&gt;Minimum&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-51-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;mean&#34;&gt;Mean&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-52-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;maximum&#34;&gt;Maximum&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-53-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;events&#34;&gt;Events&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-54-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;combining-weather-and-trip-datasets&#34;&gt;Combining Weather and Trip Datasets&lt;/h4&gt;

&lt;p&gt;Good, so we can now see some parts of the weather data. Let&amp;rsquo;s combine the weather data with our trip data. Let&amp;rsquo;s try a &lt;code&gt;left join&lt;/code&gt; from the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Make a copy of the data frame
trip_3 &amp;lt;- trip_2

# Change column name in trip_3 to match weather dataset
trip_3$Date &amp;lt;- trip_3$start_date

# Left join the trip and weather dataframes by date.
trip_weather &amp;lt;- left_join(trip_3, weather, by = &amp;quot;Date&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;mean-temperature-vs-number-of-trips&#34;&gt;Mean Temperature vs. Number of Trips&lt;/h4&gt;

&lt;p&gt;Ok. Now let&amp;rsquo;s see how the number of trips per day is influenced by weather (mean temperature, rounded to the nearest 5 degrees F)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-56-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So, as expected, there are more trips when the weather is mild but not too warm (over 70F) or too cold (below 50F). However, this figure may be influenced by the overall number of days that exhibited each mean temperature. Let&amp;rsquo;s try to standardize that.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-57-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So when we standardize our measurements, correcting for the number of days that actually reached each temperature, we see a steady increase in the number of trips until around 75F where the trend levels off. People are more likely to ride a bike when it&amp;rsquo;s warm outside.&lt;/p&gt;

&lt;h4 id=&#34;precipitation-vs-number-of-trips&#34;&gt;Precipitation vs. Number of Trips&lt;/h4&gt;

&lt;p&gt;If you&amp;rsquo;ve ever heard of Seattle, you probably hear that it rains all the time there. Let&amp;rsquo;s see if that has an impact on the number of trips taken in a day.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start with a figure standardized for number of days at a precipitation level, rounded to the nearest 0.2 inches. &lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-58-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like even Seattleites have a limit when it comes to riding a bike in the rain. The more it rained, the fewer trips were taken per day.&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;So what did we learn from all of this? In the nearly 2 years since Pronto! opened in Seattle:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;236,065 bike trips were taken using this service&lt;/li&gt;
&lt;li&gt;More trips occur in the spring and summer than winter/autumn&lt;/li&gt;
&lt;li&gt;More trips occur during warm/dry weather&lt;/li&gt;
&lt;li&gt;People tend to ride downhill more frequently than uphill&lt;/li&gt;
&lt;li&gt;Pronto! bikes are used for work commutes during the week and more leisurely use on weekends&lt;/li&gt;
&lt;li&gt;Short-Term Pass Holders are more likely to incur extra charges due to surpassing their time limit&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;suggestions-for-pronto&#34;&gt;Suggestions for Pronto!&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Give users bonuses for bringing bikes back to a station on the top of the hill&lt;/li&gt;
&lt;li&gt;Hold discounts in fall/winter&lt;/li&gt;
&lt;li&gt;Find a way to alert short-term users that their time limit will be ending soon, and where the nearest station is to them at that time&lt;/li&gt;
&lt;li&gt;Consider a 3rd membership option: &amp;ldquo;Commuter&amp;rdquo;. This may allow users to take bikes between 7-10 AM and 4-7 PM for free, but operate under a different time limit schedule during other times of day.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As always, I appreciate any and all feedback from my work and appreciate you taking the time to see what I&amp;rsquo;ve done. Thanks!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ghosts, Goblins, and Ghouls</title>
      <link>/projects/Ghosts_Goblins_Ghouls_02/</link>
      <pubDate>Wed, 09 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/projects/Ghosts_Goblins_Ghouls_02/</guid>
      <description>&lt;p&gt;Kaggle Playground Competition&lt;/p&gt;

&lt;p&gt;Data exploration and machine learning in RMarkdown.
&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#importing-data&#34;&gt;Importing Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-exploration&#34;&gt;Data Exploration&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#distribution-of-continuous-variables-by-creature-type&#34;&gt;Distribution of Continuous Variables by Creature Type&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#distribution-of-color-by-creature-type&#34;&gt;Distribution of Color by Creature Type&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#distinguishing-features&#34;&gt;Distinguishing Features?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feature-engineering&#34;&gt;Feature Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning-data&#34;&gt;Cleaning Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#clustering-data&#34;&gt;Clustering data&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#cluster-without-categorical-variables&#34;&gt;Cluster Without Categorical Variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modeling-for-creature-identity&#34;&gt;Modeling for Creature Identity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-traincontrol&#34;&gt;Creating trainControl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#random-forest-modeling&#34;&gt;Random Forest Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#glmnet-modeling&#34;&gt;GLMnet Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#comparing-model-fit&#34;&gt;Comparing model fit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#predicting-creature-identity&#34;&gt;Predicting Creature Identity&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#preparing-the-prediction-for-kaggle&#34;&gt;Preparing the prediction for Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#testing-with-kaggle&#34;&gt;Testing with Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is my second-ever Kaggle competition (looking for the &lt;a href=&#34;https://www.kaggle.com/amberthomas/titanic/predicting-survival-on-the-titanic&#34;&gt;first&lt;/a&gt;?) I&amp;rsquo;ll do my best to walk through my thought-process here and welcome any comments on my work. Let&amp;rsquo;s get started!&lt;/p&gt;

&lt;h3 id=&#34;loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# For data manipulation and tidying
library(dplyr)

# For data visualizations
library(ggplot2)
library(fpc)

# For modeling and predictions
library(caret)
library(glmnet)
library(ranger)
library(e1071)
library(clValid)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;importing-data&#34;&gt;Importing Data&lt;/h3&gt;

&lt;p&gt;The data were downloaded directly from the &lt;a href=&#34;https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo/data&#34;&gt;Kaggle Website&lt;/a&gt;. Before binding the training and test sets into a single data file, I added a column called &amp;ldquo;Dataset&amp;rdquo; and labelled rows from the training file &amp;ldquo;train&amp;rdquo; and rows from the testing file &amp;ldquo;test&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train &amp;lt;- read.csv(file = &amp;quot;train.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
train$Dataset &amp;lt;- &amp;quot;train&amp;quot;

test &amp;lt;- read.csv(file = &amp;quot;test.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
test$Dataset &amp;lt;- &amp;quot;test&amp;quot;

full &amp;lt;- bind_rows(train, test)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, time to take a look at the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(full)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    900 obs. of  8 variables:
##  $ id           : int  0 1 2 4 5 7 8 11 12 19 ...
##  $ bone_length  : num  0.355 0.576 0.468 0.777 0.566 ...
##  $ rotting_flesh: num  0.351 0.426 0.354 0.509 0.876 ...
##  $ hair_length  : num  0.466 0.531 0.812 0.637 0.419 ...
##  $ has_soul     : num  0.781 0.44 0.791 0.884 0.636 ...
##  $ color        : chr  &amp;quot;clear&amp;quot; &amp;quot;green&amp;quot; &amp;quot;black&amp;quot; &amp;quot;black&amp;quot; ...
##  $ type         : chr  &amp;quot;Ghoul&amp;quot; &amp;quot;Goblin&amp;quot; &amp;quot;Ghoul&amp;quot; &amp;quot;Ghoul&amp;quot; ...
##  $ Dataset      : chr  &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(full)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##        id         bone_length     rotting_flesh     hair_length    
##  Min.   :  0.0   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:224.8   1st Qu.:0.3321   1st Qu.:0.4024   1st Qu.:0.3961  
##  Median :449.5   Median :0.4268   Median :0.5053   Median :0.5303  
##  Mean   :449.5   Mean   :0.4291   Mean   :0.5050   Mean   :0.5222  
##  3rd Qu.:674.2   3rd Qu.:0.5182   3rd Qu.:0.6052   3rd Qu.:0.6450  
##  Max.   :899.0   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##     has_soul         color               type             Dataset         
##  Min.   :0.0000   Length:900         Length:900         Length:900        
##  1st Qu.:0.3439   Class :character   Class :character   Class :character  
##  Median :0.4655   Mode  :character   Mode  :character   Mode  :character  
##  Mean   :0.4671                                                           
##  3rd Qu.:0.5892                                                           
##  Max.   :1.0000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! So here&amp;rsquo;s what we know so far:&lt;/p&gt;

&lt;p&gt;We have 8 variables currently:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ID&lt;/strong&gt; : Appears to be the identification number of the monster in question&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bone Length&lt;/strong&gt; : Average length of the bones in the creature, normalized to 0 - 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rotting Flesh&lt;/strong&gt; : Percentage of flesh on the creature that is rotting&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hair Length&lt;/strong&gt; : Average length of the hair on the creature, normalized from 0 - 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Has Soul&lt;/strong&gt; : The percentage of a soul present in the creature&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Color&lt;/strong&gt; : The color of the creature&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt; : The category of the creature (i.e. ghoul, goblin or ghost)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dataset&lt;/strong&gt; : The column I added when importing data indicating whether the observation was part of the original training or test set&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It seems like a few of these variables would serve better as factors, rather than character strings, so I&amp;rsquo;ll take care of that.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;factor_variables &amp;lt;- c(&amp;quot;id&amp;quot;, &amp;quot;color&amp;quot;, &amp;quot;type&amp;quot;, &amp;quot;Dataset&amp;quot;)
full[factor_variables] &amp;lt;- lapply(full[factor_variables], function(x) as.factor(x))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;data-exploration&#34;&gt;Data Exploration&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at what we&amp;rsquo;ve got here so far. What&amp;rsquo;s the distribution of each variable across each monster?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s first temporarily remove the &amp;ldquo;test&amp;rdquo; rows.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train_2 &amp;lt;- full[full$Dataset == &amp;quot;train&amp;quot;, ]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;distribution-of-continuous-variables-by-creature-type&#34;&gt;Distribution of Continuous Variables by Creature Type&lt;/h3&gt;

&lt;h4 id=&#34;bone-length&#34;&gt;Bone Length&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-6-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;rotting-flesh&#34;&gt;Rotting Flesh&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-7-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;hair-length&#34;&gt;Hair Length&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-8-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;soul&#34;&gt;Soul&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-9-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;distribution-of-color-by-creature-type&#34;&gt;Distribution of Color by Creature Type&lt;/h3&gt;

&lt;h4 id=&#34;ghost&#34;&gt;Ghost&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-10-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;ghoul&#34;&gt;Ghoul&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-11-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;goblin&#34;&gt;Goblin&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-12-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;distinguishing-features&#34;&gt;Distinguishing Features?&lt;/h3&gt;

&lt;p&gt;Hmm, looks like ghosts have shorter hair and fewer pieces of soul than ghouls and goblins, but otherwise are pretty close. Ghouls and goblins are going to be tricky to distinguish. Color doesn&amp;rsquo;t appear to help a whole lot as there seems to be a pretty even distribution to these multi-colored critters.&lt;/p&gt;

&lt;h2 id=&#34;feature-engineering&#34;&gt;Feature Engineering&lt;/h2&gt;

&lt;p&gt;Normally here I would try to come up with additional ways to look at these data, but we can&amp;rsquo;t infer the size of the creature since both bone and hair length have been normalized. As of now, I can&amp;rsquo;t think of any features worth engineering from the current data.&lt;/p&gt;

&lt;p&gt;Maybe I&amp;rsquo;m missing some interesting connection between variables?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pairs(full[, 2:5], col = full$type, labels = c(&amp;quot;Bone Length&amp;quot;, 
    &amp;quot;Rotting Flesh&amp;quot;, &amp;quot;Hair Length&amp;quot;, &amp;quot;Soul&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-13-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Nope. But perhaps we can take advantage of a combination of characteristics that do seem to show some promise: most notably &amp;ldquo;Hair Length&amp;rdquo; and &amp;ldquo;Soul&amp;rdquo;. Do we get any better separation among creatures if we combine these variables into one?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full &amp;lt;- full %&amp;gt;% mutate(hair_soul = hair_length * has_soul)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-15-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That may have separated Ghosts a little further from the other two&amp;hellip; Let&amp;rsquo;s try a few more variable interactions.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full &amp;lt;- full %&amp;gt;% mutate(bone_flesh = bone_length * rotting_flesh, 
    bone_hair = bone_length * hair_length, bone_soul = bone_length * 
        has_soul, flesh_hair = rotting_flesh * hair_length, flesh_soul = rotting_flesh * 
        has_soul)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Time to check for ways to tidy up.&lt;/p&gt;

&lt;h2 id=&#34;cleaning-data&#34;&gt;Cleaning Data&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s take another look at the summary statistics for this dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(full)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##        id       bone_length     rotting_flesh     hair_length    
##  0      :  1   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1      :  1   1st Qu.:0.3321   1st Qu.:0.4024   1st Qu.:0.3961  
##  2      :  1   Median :0.4268   Median :0.5053   Median :0.5303  
##  3      :  1   Mean   :0.4291   Mean   :0.5050   Mean   :0.5222  
##  4      :  1   3rd Qu.:0.5182   3rd Qu.:0.6052   3rd Qu.:0.6450  
##  5      :  1   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##  (Other):894                                                     
##     has_soul        color         type      Dataset      hair_soul     
##  Min.   :0.0000   black:104   Ghost :117   test :529   Min.   :0.0000  
##  1st Qu.:0.3439   blood: 21   Ghoul :129   train:371   1st Qu.:0.1322  
##  Median :0.4655   blue : 54   Goblin:125               Median :0.2448  
##  Mean   :0.4671   clear:292   NA&#39;s  :529               Mean   :0.2588  
##  3rd Qu.:0.5892   green: 95                            3rd Qu.:0.3631  
##  Max.   :1.0000   white:334                            Max.   :0.7768  
##                                                                        
##    bone_flesh       bone_hair        bone_soul        flesh_hair    
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.1473   1st Qu.:0.1361   1st Qu.:0.1136   1st Qu.:0.1847  
##  Median :0.2039   Median :0.2194   Median :0.1944   Median :0.2473  
##  Mean   :0.2159   Mean   :0.2330   Mean   :0.2098   Mean   :0.2585  
##  3rd Qu.:0.2701   3rd Qu.:0.3191   3rd Qu.:0.2810   3rd Qu.:0.3242  
##  Max.   :0.7887   Max.   :0.7779   Max.   :0.6869   Max.   :0.7478  
##                                                                     
##    flesh_soul    
##  Min.   :0.0000  
##  1st Qu.:0.1539  
##  Median :0.2163  
##  Mean   :0.2316  
##  3rd Qu.:0.2991  
##  Max.   :0.7195  
## 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only column that has any missing values is &lt;code&gt;type&lt;/code&gt; which is to be expected since that&amp;rsquo;s what we need to be predicting. Everything else seems to look good so far. Let&amp;rsquo;s try to model these as is.&lt;/p&gt;

&lt;h2 id=&#34;clustering-data&#34;&gt;Clustering data&lt;/h2&gt;

&lt;p&gt;While clustering is generally used for unsupervised machine learning, I want to take a peek at the clusters that could be formed using the data at hand. The potential issue with trying to cluster this data is that we are working with two types of data: continuous and categorical. They break down like this:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Continuous Variables&lt;/th&gt;
&lt;th&gt;Categorical Variables&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;bone length&lt;/td&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;rotting flesh&lt;/td&gt;
&lt;td&gt;color&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;hair length&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;has soul&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;So, sure, there&amp;rsquo;s only two categorical variables. Because of our small sample size, it&amp;rsquo;s not a good idea to count out these variables completely, but we&amp;rsquo;ll try to create clusters without them just to see how well the clustering models do.&lt;/p&gt;

&lt;h3 id=&#34;cluster-without-categorical-variables&#34;&gt;Cluster Without Categorical Variables&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;ll first try to cluster using the &lt;code&gt;kmeans&lt;/code&gt; function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Set the seed
set.seed(100)

# Extract creature labels and remove column from dataset
creature_labels &amp;lt;- full$type
full2 &amp;lt;- full
full2$type &amp;lt;- NULL

# Remove categorical variables (id, color, and dataset) from
# dataset
full2$id &amp;lt;- NULL
full2$color &amp;lt;- NULL
full2$Dataset &amp;lt;- NULL

# Perform k-means clustering with 3 clusters, repeat 30 times
creature_km_1 &amp;lt;- kmeans(full2, 3, nstart = 30)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so now we have clusters, time to see how well they did. Let&amp;rsquo;s look at them graphically first. This was created using the &lt;code&gt;plotcluster()&lt;/code&gt; function from the &lt;code&gt;fpc&lt;/code&gt; package.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-19-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hmm, those clusters don&amp;rsquo;t look very discrete. Let&amp;rsquo;s look at &lt;a href=&#34;https://en.wikipedia.org/wiki/Dunn_index&#34;&gt;Dunn&amp;rsquo;s Index&lt;/a&gt; mathematically to see if we&amp;rsquo;re missing something visually. This calculation comes from the &lt;code&gt;dunn&lt;/code&gt; function in the &lt;code&gt;clValid&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dunn_ckm_1 &amp;lt;- dunn(clusters = creature_km_1$cluster, Data = full2)

# Print results
dunn_ckm_1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 0.04670431
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As Dunn&amp;rsquo;s Index represents a ratio of the smallest distance between clusters to the largest distance between two points in the same cluster (or, the smallest inter-cluster distance to the largest intra-cluster distance), such a low number indicates that our current clusters are not condensed, separate entities. This is not terribly surprising considering we completely disregarded one of our variables.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how well this clustering method correctly separated the labelled creatures.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(creature_km_1$cluster, creature_labels)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    creature_labels
##     Ghost Ghoul Goblin
##   1     7    39     75
##   2     4    86     24
##   3   106     4     26
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like currently, ghosts were separated relatively well, but ghouls and goblins are split between the clusters. Ok, I&amp;rsquo;m convinced. I haven&amp;rsquo;t really gained any new information here, but it&amp;rsquo;s been an interesting exploratory path!&lt;/p&gt;

&lt;p&gt;On to supervised modeling!&lt;/p&gt;

&lt;h3 id=&#34;modeling-for-creature-identity&#34;&gt;Modeling for Creature Identity&lt;/h3&gt;

&lt;p&gt;Clustering was not particularly helpful in discerning creature identity, so perhaps creating models will work better.&lt;/p&gt;

&lt;p&gt;First things first, I need to split out the test and training data back into separate datasets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train_complete &amp;lt;- full[full$Dataset == &amp;quot;train&amp;quot;, ]
test_complete &amp;lt;- full[full$Dataset == &amp;quot;test&amp;quot;, ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because I plan on using the &lt;code&gt;caret&lt;/code&gt; package for all of my modeling, I&amp;rsquo;m going to generate a standard &lt;code&gt;trainControl&lt;/code&gt; so that those tuning parameters remain consistent throughout the various models.&lt;/p&gt;

&lt;h3 id=&#34;creating-traincontrol&#34;&gt;Creating trainControl&lt;/h3&gt;

&lt;p&gt;I will create a system that will perform 20 repeats of a 10-Fold cross-validation of the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;myControl &amp;lt;- trainControl(method = &amp;quot;cv&amp;quot;, number = 10, repeats = 20, 
    verboseIter = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;random-forest-modeling&#34;&gt;Random Forest Modeling&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s start with a random forest model, generated using the &lt;code&gt;ranger&lt;/code&gt; and &lt;code&gt;caret&lt;/code&gt; packages. I&amp;rsquo;m going to include all of the original variables, including any interactions here.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(10)

rf_model &amp;lt;- train(type ~ bone_length + rotting_flesh + hair_length + 
    has_soul + color + hair_soul + bone_flesh + bone_hair + bone_soul + 
    flesh_hair + flesh_soul, tuneLength = 3, data = train_complete, 
    method = &amp;quot;ranger&amp;quot;, trControl = myControl, importance = &amp;quot;impurity&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at the levels of importance of each factor in this model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-25-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Huh. Our &amp;ldquo;hair_soul&amp;rdquo; variable seems to be the most important to this model and our other interactions rank pretty highly. I suppose we can hold on to them for now. Color, on the other hand, hardly plays into this. Let&amp;rsquo;s try removing it from a second random forest model.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(10)

rf_model_2 &amp;lt;- train(type ~ bone_length + rotting_flesh + hair_length + 
    has_soul + hair_soul + bone_flesh + bone_hair + bone_soul + 
    flesh_hair + flesh_soul, tuneLength = 3, data = train_complete, 
    method = &amp;quot;ranger&amp;quot;, trControl = myControl, importance = &amp;quot;impurity&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;glmnet-modeling&#34;&gt;GLMnet Modeling&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;m going to follow the random forest model up with a glmnet model, also from the &lt;code&gt;caret&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(10)

glm_model &amp;lt;- train(type ~ bone_length + rotting_flesh + hair_length + 
    has_soul + color + hair_soul + bone_flesh + bone_hair + bone_soul + 
    flesh_hair + flesh_soul, method = &amp;quot;glmnet&amp;quot;, tuneGrid = expand.grid(alpha = 0:1, 
    lambda = seq(1e-04, 1, length = 20)), data = train_complete, 
    trControl = myControl)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once again, we&amp;rsquo;ll try without &amp;ldquo;color&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(10)

glm_model_2 &amp;lt;- train(type ~ bone_length + rotting_flesh + hair_length + 
    has_soul + hair_soul + bone_flesh + bone_hair + bone_soul + 
    flesh_hair + flesh_soul, method = &amp;quot;glmnet&amp;quot;, tuneGrid = expand.grid(alpha = 0:1, 
    lambda = seq(1e-04, 1, length = 20)), data = train_complete, 
    trControl = myControl)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;comparing-model-fit&#34;&gt;Comparing model fit&lt;/h3&gt;

&lt;p&gt;Now that we have two random forest models and two glmnet models, it&amp;rsquo;s time to compare their fit.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a list of models
models &amp;lt;- list(rf = rf_model, rf2 = rf_model_2, glmnet = glm_model, 
    glmnet2 = glm_model_2)

# Resample the models
resampled &amp;lt;- resamples(models)

# Generate a summary
summary(resampled)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 
## Call:
## summary.resamples(object = resampled)
## 
## Models: rf, rf2, glmnet, glmnet2 
## Number of resamples: 10 
## 
## Accuracy 
##           Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## rf      0.6389  0.6888 0.7201 0.7194  0.7566 0.7838    0
## rf2     0.6667  0.6888 0.7105 0.7195  0.7500 0.7895    0
## glmnet  0.6842  0.7222 0.7333 0.7438  0.7616 0.8649    0
## glmnet2 0.6842  0.7047 0.7500 0.7547  0.7829 0.8649    0
## 
## Kappa 
##           Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## rf      0.4577  0.5337 0.5801 0.5789  0.6347 0.6754    0
## rf2     0.4977  0.5337 0.5664 0.5791  0.6247 0.6837    0
## glmnet  0.5265  0.5833 0.5988 0.6156  0.6428 0.7965    0
## glmnet2 0.5260  0.5555 0.6254 0.6321  0.6758 0.7965    0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Plot the differences between model fits
dotplot(resampled, metric = &amp;quot;Accuracy&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-29-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;predicting-creature-identity&#34;&gt;Predicting Creature Identity&lt;/h2&gt;

&lt;p&gt;Although I generated four models above, the second glmnet model (all interactions but without color) provided the highest accuracy, so I&amp;rsquo;ll use that model to predict survival in the test set.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Reorder the data by creature ID number
test_complete &amp;lt;- test_complete %&amp;gt;% arrange(id)

# Make predicted survival values
my_prediction &amp;lt;- predict(glm_model_2, test_complete)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;preparing-the-prediction-for-kaggle&#34;&gt;Preparing the prediction for Kaggle&lt;/h3&gt;

&lt;p&gt;The instructions on Kaggle indicate that they are expecting a csv file with 2 columns: ID and Creature Type. I need to make sure that my data are arranged properly.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a data frame with two columns
my_solution_GGG_03 &amp;lt;- data.frame(id = test_complete$id, Type = my_prediction)

# Write the solution to a csv file
write.csv(my_solution_GGG_03, file = &amp;quot;my_solution_GGG_03.csv&amp;quot;, 
    row.names = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;testing-with-kaggle&#34;&gt;Testing with Kaggle&lt;/h3&gt;

&lt;p&gt;Looks like that submission scored 0.74669! Not bad!!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I&amp;rsquo;d love to hear any feedback you may have on this process. Thanks in advance!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Machine Learning from Disaster</title>
      <link>/projects/Titanic_md/</link>
      <pubDate>Sat, 05 Nov 2016 18:25:22 +0530</pubDate>
      
      <guid>/projects/Titanic_md/</guid>
      <description>&lt;p&gt;Kaggle Playground Competition&lt;/p&gt;

&lt;p&gt;Data exploration and machine learning in RMarkdown.
&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#importing-data&#34;&gt;Importing Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feature-engineering&#34;&gt;Feature Engineering&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#names-and-titles&#34;&gt;Names and Titles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sibsp-and-parch-for-family-size&#34;&gt;SibSp and Parch for Family Size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ticket-numbers-and-travel-groups&#34;&gt;Ticket Numbers and Travel Groups&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#missing-data&#34;&gt;Missing Data&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#missing-fare&#34;&gt;Missing Fare&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#missing-embarkment&#34;&gt;Missing Embarkment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#missing-age&#34;&gt;Missing Age&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modeling-for-survival&#34;&gt;Modeling for Survival&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#creating-traincontrol&#34;&gt;Creating trainControl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-a-random-forest-model&#34;&gt;Fitting a random forest model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-a-glmnet-model&#34;&gt;Fitting a glmnet model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#comparing-model-fit&#34;&gt;Comparing model fit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#predicting-survival&#34;&gt;Predicting Survival&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#preparing-the-prediction-for-kaggle&#34;&gt;Preparing the prediction for Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#testing-with-kaggle&#34;&gt;Testing with Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is my first project on Kaggle and my first attempt at machine learning. I&amp;rsquo;ll do my best to illustrate what I&amp;rsquo;ve down and the logic behind my actions, but feedback is very much welcome and appreciated!&lt;/p&gt;

&lt;h3 id=&#34;loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# For data manipulation and tidying
library(dplyr)

# For data visualizations
library(ggplot2)

# For modeling and predictions
library(caret)
library(glmnet)
library(ranger)
library(e1071)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;importing-data&#34;&gt;Importing Data&lt;/h3&gt;

&lt;p&gt;The data were downloaded directly from the &lt;a href=&#34;https://www.kaggle.com/c/titanic/data&#34;&gt;Kaggle Website&lt;/a&gt;. Before binding the training and test sets into a single data file, I added a column called &amp;ldquo;Dataset&amp;rdquo; and labelled rows from the training file &amp;ldquo;train&amp;rdquo; and rows from the testing file &amp;ldquo;test&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train &amp;lt;- read.csv(file = &amp;quot;train.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
train$Dataset &amp;lt;- &amp;quot;train&amp;quot;

test &amp;lt;- read.csv(file = &amp;quot;test.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
test$Dataset &amp;lt;- &amp;quot;test&amp;quot;

full &amp;lt;- bind_rows(train, test)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The full dataset can then be inspected:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(full)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    1309 obs. of  13 variables:
##  $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...
##  $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...
##  $ Name       : chr  &amp;quot;Braund, Mr. Owen Harris&amp;quot; &amp;quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&amp;quot; &amp;quot;Heikkinen, Miss. Laina&amp;quot; &amp;quot;Futrelle, Mrs. Jacques Heath (Lily May Peel)&amp;quot; ...
##  $ Sex        : chr  &amp;quot;male&amp;quot; &amp;quot;female&amp;quot; &amp;quot;female&amp;quot; &amp;quot;female&amp;quot; ...
##  $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...
##  $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...
##  $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...
##  $ Ticket     : chr  &amp;quot;A/5 21171&amp;quot; &amp;quot;PC 17599&amp;quot; &amp;quot;STON/O2. 3101282&amp;quot; &amp;quot;113803&amp;quot; ...
##  $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...
##  $ Cabin      : chr  &amp;quot;&amp;quot; &amp;quot;C85&amp;quot; &amp;quot;&amp;quot; &amp;quot;C123&amp;quot; ...
##  $ Embarked   : chr  &amp;quot;S&amp;quot; &amp;quot;C&amp;quot; &amp;quot;S&amp;quot; &amp;quot;S&amp;quot; ...
##  $ Dataset    : chr  &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It appears that several of these variables should be represented as factors and thus should be reclassified.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;factor_variables &amp;lt;- c(&amp;quot;PassengerId&amp;quot;, &amp;quot;Survived&amp;quot;, &amp;quot;Pclass&amp;quot;, &amp;quot;Sex&amp;quot;, 
    &amp;quot;Embarked&amp;quot;, &amp;quot;Dataset&amp;quot;)
full[factor_variables] &amp;lt;- lapply(full[factor_variables], function(x) as.factor(x))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are now left with the following variables:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Passenger ID&lt;/strong&gt; : A seemingly unique number assigned to each passenger&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Survived&lt;/strong&gt; : A binary indicator of survival (0 = died, 1 = survived)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pclass&lt;/strong&gt; : A proxy for socio-economic status (1 = upper, 3 = lower)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Name&lt;/strong&gt; : Passenger&amp;rsquo;s Name. For wedded women, her husband&amp;rsquo;s name appears first and her maiden name appears in parentheses&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sex&lt;/strong&gt; : General indication of passenger&amp;rsquo;s sex&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Age&lt;/strong&gt; : Age of passenger (or approximate age). Passengers under the age of 1 year have fractional ages&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;SibSp&lt;/strong&gt; : A count of the passenger&amp;rsquo;s siblings or spouses aboard&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Parch&lt;/strong&gt; : A count of the passenger&amp;rsquo;s parents or siblings aboard&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ticket&lt;/strong&gt; : The number printed on the ticket. The numbering system is not immediately apparent&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Fare&lt;/strong&gt; : The price for the ticket (presumably in pounds, shillings, and pennies)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Cabin&lt;/strong&gt; : Cabin number occupied by the passenger (this field is quite empty)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Embarked&lt;/strong&gt; : The port from which the passenger boarded the ship&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dataset&lt;/strong&gt; : Whether this particular row was a part of the training or testing dataset&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;feature-engineering&#34;&gt;Feature Engineering&lt;/h2&gt;

&lt;h3 id=&#34;names-and-titles&#34;&gt;Names and Titles&lt;/h3&gt;

&lt;p&gt;At first glance, the &amp;ldquo;Name&amp;rdquo; column doesn&amp;rsquo;t help too much as there are 1307 unique names, however, this column also includes embedded title information that may be of interest. I decided to use &lt;a href=&#34;https://www.rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf&#34;&gt;regular expressions&lt;/a&gt; and the &lt;code&gt;gsub()&lt;/code&gt; functions to extract the titles into a new variable.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;names &amp;lt;- full$Name

titles &amp;lt;- gsub(&amp;quot;^.*, (.*?)\\..*$&amp;quot;, &amp;quot;\\1&amp;quot;, names)

full$Titles &amp;lt;- titles

unique(full$Titles)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Mr&amp;quot;           &amp;quot;Mrs&amp;quot;          &amp;quot;Miss&amp;quot;         &amp;quot;Master&amp;quot;      
##  [5] &amp;quot;Don&amp;quot;          &amp;quot;Rev&amp;quot;          &amp;quot;Dr&amp;quot;           &amp;quot;Mme&amp;quot;         
##  [9] &amp;quot;Ms&amp;quot;           &amp;quot;Major&amp;quot;        &amp;quot;Lady&amp;quot;         &amp;quot;Sir&amp;quot;         
## [13] &amp;quot;Mlle&amp;quot;         &amp;quot;Col&amp;quot;          &amp;quot;Capt&amp;quot;         &amp;quot;the Countess&amp;quot;
## [17] &amp;quot;Jonkheer&amp;quot;     &amp;quot;Dona&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s a bit more manageable: only 18 unique titles. Time to see how many times each title was used. I decided to make a table separated by sex.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(full$Sex, full$Title)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##         
##          Capt Col Don Dona  Dr Jonkheer Lady Major Master Miss Mlle Mme
##   female    0   0   0    1   1        0    1     0      0  260    2   1
##   male      1   4   1    0   7        1    0     2     61    0    0   0
##         
##           Mr Mrs  Ms Rev Sir the Countess
##   female   0 197   2   0   0            1
##   male   757   0   0   8   1            0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like Captain, Don, Dona, Jonkheer, Lady, Madame, Sir and the Countess were each only used once. I&amp;rsquo;ll leave Captain separate, but the rest should be combined with similar categories.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Don&lt;/strong&gt; : A Spanish/Portuguese/Italian title used with, but not instead of, a name.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dona&lt;/strong&gt; : Female version of &amp;ldquo;Don&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jonkheer&lt;/strong&gt; : Dutch honorific of nobility&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lady&lt;/strong&gt; : English honorific of nobility&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Madame&lt;/strong&gt; : French, polite form of address for a woman&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sir&lt;/strong&gt; : Honorific address (male)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;the Countess&lt;/strong&gt; : Rank of nobility (female)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It seems that most of the rarely used titles indicate some form of nobility. That&amp;rsquo;s easy to check with another table comparing &lt;code&gt;Pclass&lt;/code&gt; and &lt;code&gt;Titles&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(full$Pclass, full$Titles)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    
##     Capt Col Don Dona  Dr Jonkheer Lady Major Master Miss Mlle Mme  Mr Mrs
##   1    1   4   1    1   6        1    1     2      5   60    2   1 159  77
##   2    0   0   0    0   2        0    0     0     11   50    0   0 150  55
##   3    0   0   0    0   0        0    0     0     45  150    0   0 448  65
##    
##      Ms Rev Sir the Countess
##   1   0   0   1            1
##   2   1   8   0            0
##   3   1   0   0            0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since Don, Jonkheer, and Sir are all of similar usage, and each represent only one first-class man, I combined them into the category &amp;ldquo;Sir&amp;rdquo;. Dona, Lady, Madame, and the Countess each only represent one first-class woman, so I combined them into the category &amp;ldquo;Lady&amp;rdquo;. These values were substituted using the &lt;code&gt;gsub&lt;/code&gt; function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full$Titles &amp;lt;- gsub(&amp;quot;Dona|Lady|Madame|the Countess&amp;quot;, &amp;quot;Lady&amp;quot;, 
    full$Titles)
full$Titles &amp;lt;- gsub(&amp;quot;Don|Jonkheer|Sir&amp;quot;, &amp;quot;Sir&amp;quot;, full$Titles)

unique(full$Titles)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Mr&amp;quot;     &amp;quot;Mrs&amp;quot;    &amp;quot;Miss&amp;quot;   &amp;quot;Master&amp;quot; &amp;quot;Sir&amp;quot;    &amp;quot;Rev&amp;quot;    &amp;quot;Dr&amp;quot;    
##  [8] &amp;quot;Mme&amp;quot;    &amp;quot;Ms&amp;quot;     &amp;quot;Major&amp;quot;  &amp;quot;Lady&amp;quot;   &amp;quot;Mlle&amp;quot;   &amp;quot;Col&amp;quot;    &amp;quot;Capt&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: If you are planning to replicate the above substitution without any RegEx, make sure that you substitute &amp;ldquo;Dona&amp;rdquo; before substituting &amp;ldquo;Don&amp;rdquo;! Otherwise, &amp;ldquo;Dona&amp;rdquo; becomes &amp;ldquo;Sira&amp;rdquo; (as the &amp;ldquo;Don&amp;rdquo; part was replaced with &amp;ldquo;Sir&amp;rdquo;) and your second substitution won&amp;rsquo;t find or replace &amp;ldquo;Dona&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Lastly for the titles, they should be factors, not character strings.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full$Titles &amp;lt;- as.factor(full$Titles)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These titles could certainly be condensed more, but for the time being, I am going to leave them separated as is.&lt;/p&gt;

&lt;p&gt;I have some thoughts about wanting to split up the names further to find family groups, but since many familial relationships (cousins, nieces/nephews, aunts/uncles, fiances, mistresses, in-laws, children with a nanny or close friends) aren&amp;rsquo;t reported in any way in this data set, I&amp;rsquo;ll have to think a little longer about the most appropriate way to find actual family groups.&lt;/p&gt;

&lt;h3 id=&#34;sibsp-and-parch-for-family-size&#34;&gt;SibSp and Parch for Family Size&lt;/h3&gt;

&lt;p&gt;Since the SibSp and Parch variables each give some indication as to close family members that were also aboard the ship, it would make sense to calculate family size as a combination of SibSp, Parch and the passenger in question.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full &amp;lt;- mutate(full, FamilySize = SibSp + Parch + 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s visualize family size&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-11-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Lots of people without immediate family with them. Perhaps these people were traveling with other family members/friends that weren&amp;rsquo;t captured in the SibSp / Parch variables.&lt;/p&gt;

&lt;h3 id=&#34;ticket-numbers-and-travel-groups&#34;&gt;Ticket Numbers and Travel Groups&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;ve decided that another possible way to discern groups that were travelling together is to look at the ticket numbers. It appears that families or groups who purchased their tickets together have identical ticket numbers, thus quantifying the number of families or traveling groups. A quick look at the unique ticket numbers indicates there are 929 of them in the full data set (out of a possible 1309 passengers).&lt;/p&gt;

&lt;p&gt;It seems the easiest way to separate these tickets is to create a new column:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full$TravelGroup &amp;lt;- NA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then arrange the data by ticket number using the &lt;code&gt;arrange()&lt;/code&gt; function from the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full2 &amp;lt;- arrange(full, Ticket)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Take a look at the first few rows of results&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(full2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   PassengerId Survived Pclass
## 1         258        1      1
## 2         505        1      1
## 3         760        1      1
## 4         263        0      1
## 5         559        1      1
## 6         586        1      1
##                                                       Name    Sex Age
## 1                                     Cherry, Miss. Gladys female  30
## 2                                    Maioni, Miss. Roberta female  16
## 3 Rothes, the Countess. of (Lucy Noel Martha Dyer-Edwards) female  33
## 4                                        Taussig, Mr. Emil   male  52
## 5                   Taussig, Mrs. Emil (Tillie Mandelbaum) female  39
## 6                                      Taussig, Miss. Ruth female  18
##   SibSp Parch Ticket  Fare Cabin Embarked Dataset Titles FamilySize
## 1     0     0 110152 86.50   B77        S   train   Miss          1
## 2     0     0 110152 86.50   B79        S   train   Miss          1
## 3     0     0 110152 86.50   B77        S   train   Lady          1
## 4     1     1 110413 79.65   E67        S   train     Mr          3
## 5     1     1 110413 79.65   E67        S   train    Mrs          3
## 6     0     2 110413 79.65   E68        S   train   Miss          3
##   TravelGroup
## 1          NA
## 2          NA
## 3          NA
## 4          NA
## 5          NA
## 6          NA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To verify that this is working so far, I inspected the first ticket number listed (110152) on the &lt;a href=&#34;https://www.encyclopedia-titanica.org/titanic-passengers-and-crew/&#34;&gt;Titanic Passenger and Crew&lt;/a&gt; table of Encyclopedia Titanica. That dataset lists the same three passengers owned those tickets, verified that the 3 women were traveling together, and indicated that two of the women (Miss Gladys Cherry and the Countess of Rothes) were cousins and the 3rd woman in their party (Miss Roberta Elizabeth Mary Maioni) was their servant. Looking at unique Ticket ID may be the only way to know that these women were travelling together. I&amp;rsquo;m feeling good that unique ticket numbers may be a good way to look at family/traveling groups, so full steam ahead!&lt;/p&gt;

&lt;p&gt;Next, I need to generate a &amp;ldquo;TravelGroup&amp;rdquo; number. To do this, I will use the &lt;code&gt;transform&lt;/code&gt; function looking for matching unique Ticket numbers.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full2 &amp;lt;- (transform(full2, TravelGroup = match(Ticket, unique(Ticket))))

# Can&#39;t forget to make those Travel Groups into factors!
full2$TravelGroup &amp;lt;- as.factor(full2$TravelGroup)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This generates 929 unique Travel Groups, which is the same number of unique Ticket numbers. So far so good.&lt;/p&gt;

&lt;p&gt;It may also be of interest to look at group size. We can generate this using the &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;mutate&lt;/code&gt; functions in &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full3 &amp;lt;- full2 %&amp;gt;% group_by(TravelGroup) %&amp;gt;% mutate(GroupSize = n()) %&amp;gt;% 
    ungroup()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How does Travel Group Size compare to Family Group Size that we calculated earlier?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-17-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-17-2.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;They look pretty close, again showing that most people were potentially travelling alone.&lt;/p&gt;

&lt;p&gt;Now to check if those with the unique Ticket IDs were really travelling alone:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;filtered &amp;lt;- filter(full3, GroupSize == 1)

# How many were listed as being onboard with siblings or
# spouses?
fSibSp &amp;lt;- filtered[filtered$SibSp &amp;gt; 0, ]
nrow(fSibSp)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 42
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# How many were listed as being onboard with parents or
# children?
fParch &amp;lt;- filtered[filtered$Parch &amp;gt; 0, ]
nrow(fParch)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 16
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# How many of those people overlapped both groups?
sum(fSibSp$PassengerId %in% fParch$PassengerId)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Oops! Looks like we were counting 50 passengers as solo-riders when they were actually riding with family. Given the current information, I&amp;rsquo;m not sure how to know to tell who was travelling together. Manually summing SibSp and Parch to estimate family size doesn&amp;rsquo;t account for other types of groups that were travelling together and looking only at unique Ticket Number doesn&amp;rsquo;t account for some travelling with family who purchased a separate ticket. I could override the GroupSize for those 50 that weren&amp;rsquo;t actually riding solo, but their TravelGroup number won&amp;rsquo;t be accurate. For the time being, I&amp;rsquo;m going to leave TravelGroup and GroupSize as is.&lt;/p&gt;

&lt;h2 id=&#34;missing-data&#34;&gt;Missing Data&lt;/h2&gt;

&lt;p&gt;At this point, I&amp;rsquo;m feeling pretty good about the Feature Engineering that I&amp;rsquo;ve done so far. Time to correct for missing data!&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at what has NA values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(full3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   PassengerId   Survived   Pclass      Name               Sex     
##  1      :   1   0   :549   1:323   Length:1309        female:466  
##  2      :   1   1   :342   2:277   Class :character   male  :843  
##  3      :   1   NA&#39;s:418   3:709   Mode  :character               
##  4      :   1                                                     
##  5      :   1                                                     
##  6      :   1                                                     
##  (Other):1303                                                     
##       Age            SibSp            Parch          Ticket         
##  Min.   : 0.17   Min.   :0.0000   Min.   :0.000   Length:1309       
##  1st Qu.:21.00   1st Qu.:0.0000   1st Qu.:0.000   Class :character  
##  Median :28.00   Median :0.0000   Median :0.000   Mode  :character  
##  Mean   :29.88   Mean   :0.4989   Mean   :0.385                     
##  3rd Qu.:39.00   3rd Qu.:1.0000   3rd Qu.:0.000                     
##  Max.   :80.00   Max.   :8.0000   Max.   :9.000                     
##  NA&#39;s   :263                                                        
##       Fare            Cabin           Embarked  Dataset        Titles   
##  Min.   :  0.000   Length:1309         :  2    test :418   Mr     :757  
##  1st Qu.:  7.896   Class :character   C:270    train:891   Miss   :260  
##  Median : 14.454   Mode  :character   Q:123                Mrs    :197  
##  Mean   : 33.295                      S:914                Master : 61  
##  3rd Qu.: 31.275                                           Dr     :  8  
##  Max.   :512.329                                           Rev    :  8  
##  NA&#39;s   :1                                                 (Other): 18  
##    FamilySize      TravelGroup     GroupSize     
##  Min.   : 1.000   779    :  11   Min.   : 1.000  
##  1st Qu.: 1.000   105    :   8   1st Qu.: 1.000  
##  Median : 1.000   776    :   8   Median : 1.000  
##  Mean   : 1.884   336    :   7   Mean   : 2.102  
##  3rd Qu.: 2.000   455    :   7   3rd Qu.: 3.000  
##  Max.   :11.000   460    :   7   Max.   :11.000  
##                   (Other):1261
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like we are missing values in the &amp;ldquo;Survived&amp;rdquo; variable (which is to be expected since this is a combination of the training and test datasets), &amp;ldquo;Fare&amp;rdquo;, &amp;ldquo;Embarked&amp;rdquo;, and quite a few in the &amp;ldquo;Age&amp;rdquo; column. We&amp;rsquo;ll start with &amp;ldquo;Fare&amp;rdquo;.&lt;/p&gt;

&lt;h3 id=&#34;missing-fare&#34;&gt;Missing Fare&lt;/h3&gt;

&lt;p&gt;Which passenger has no fare information?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full3[(which(is.na(full3$Fare))), 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 1
##   PassengerId
##        &amp;lt;fctr&amp;gt;
## 1        1044
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like Passenger number 1044 has no listed Fare.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Resort the dataset by Passenger Number
full4 &amp;lt;- arrange(full3, PassengerId)

# Where did this passenger leave from? What was their class?
full4[1044, c(3, 12)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   Pclass Embarked
##   &amp;lt;fctr&amp;gt;   &amp;lt;fctr&amp;gt;
## 1      3        S
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like he left from &amp;rsquo;S&amp;rsquo; (Southampton) as a 3rd class passenger. Let&amp;rsquo;s see what other people of the same class and embarkment port paid for their tickets.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-22-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4 %&amp;gt;% filter(Pclass == &amp;quot;3&amp;quot; &amp;amp; Embarked == &amp;quot;S&amp;quot;) %&amp;gt;% summarise(missing_fare = median(Fare, 
    na.rm = TRUE))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 1
##   missing_fare
##          &amp;lt;dbl&amp;gt;
## 1         8.05
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like the median cost for a 3rd class passenger leaving out of Southampton was 8.05. That seems like a logical value for this passenger to have paid.&lt;/p&gt;

&lt;p&gt;Time to replace that NA with 8.05&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4$Fare[1044] &amp;lt;- 8.05

summary(full4$Fare)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.000   7.896  14.450  33.280  31.280 512.300
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hooray! No more NA values for Fare.&lt;/p&gt;

&lt;h3 id=&#34;missing-embarkment&#34;&gt;Missing Embarkment&lt;/h3&gt;

&lt;p&gt;Which passengers have no listed embarkment port?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4$Embarked[full4$Embarked == &amp;quot;&amp;quot;] &amp;lt;- NA

full4[(which(is.na(full4$Embarked))), 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 1
##   PassengerId
##        &amp;lt;fctr&amp;gt;
## 1          62
## 2         830
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so Passenger numbers 62 and 830 are each missing their embarkment ports. Let&amp;rsquo;s look at their class of ticket and their fare.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4[c(62, 830), c(1, 3, 10)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 3
##   PassengerId Pclass  Fare
##        &amp;lt;fctr&amp;gt; &amp;lt;fctr&amp;gt; &amp;lt;dbl&amp;gt;
## 1          62      1    80
## 2         830      1    80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Both passengers had first class tickets that they spent 80 (pounds?) on. Let&amp;rsquo;s see the embarkment ports of others who bought similar kinds of tickets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4 %&amp;gt;% group_by(Embarked, Pclass) %&amp;gt;% filter(Pclass == &amp;quot;1&amp;quot;) %&amp;gt;% 
    summarise(mfare = median(Fare), n = n())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [4 x 4]
## Groups: Embarked [?]
## 
##   Embarked Pclass   mfare     n
##     &amp;lt;fctr&amp;gt; &amp;lt;fctr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1        C      1 76.7292   141
## 2        Q      1 90.0000     3
## 3        S      1 52.0000   177
## 4       NA      1 80.0000     2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like the median price for a first class ticket departing from &amp;lsquo;C&amp;rsquo; (Charbourg) was 77 (in comparison to our 80). While first class tickets departing from &amp;lsquo;Q&amp;rsquo; were only slightly more expensive (median price 90), only 3 first class passengers departed from that port. It seems far more likely that passengers 62 and 830 departed with the other 141 first-class passengers from Charbourg.&lt;/p&gt;

&lt;p&gt;Now to replace their NA values with &amp;lsquo;C&amp;rsquo;. And drop any unused levels.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Assign empty embark ports to &#39;C&#39;
full4$Embarked[c(62, 830)] &amp;lt;- &amp;quot;C&amp;quot;

# Drop unused levels (since there should be no more blanks)
full4$Embarked &amp;lt;- droplevels(full4$Embarked)

# Check to make sure there are no NA&#39;s or blanks
levels(full4$Embarked)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;C&amp;quot; &amp;quot;Q&amp;quot; &amp;quot;S&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yay! No more NA values for Embarked.&lt;/p&gt;

&lt;h3 id=&#34;missing-age&#34;&gt;Missing Age&lt;/h3&gt;

&lt;p&gt;This one is a bit trickier. 263 passengers have no age listed. Taking a median age of all passengers doesn&amp;rsquo;t seem like the best way to solve this problem, so it may be easiest to try to predict the passengers&amp;rsquo; age based on other known information.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve decided to use the &lt;code&gt;caret&lt;/code&gt; package for predicting age.&lt;/p&gt;

&lt;p&gt;Generate a random forest model on the full dataset (minus the age values that are NA)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;predicted_age &amp;lt;- train(Age ~ Pclass + Sex + SibSp + Parch + Fare + 
    Embarked + Titles + FamilySize + GroupSize, tuneGrid = data.frame(mtry = c(2, 
    3, 7)), data = full4[!is.na(full4$Age), ], method = &amp;quot;ranger&amp;quot;, 
    trControl = trainControl(method = &amp;quot;cv&amp;quot;, number = 10, repeats = 10, 
        verboseIter = TRUE), importance = &amp;quot;impurity&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at what factors were the most important in modeling age:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-30-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Looks like it was a good idea to split out Titles!&lt;/p&gt;

&lt;p&gt;Now to use this information to predict the ages of passengers with missing ages and filling in their NA values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4$Age[is.na(full4$Age)] &amp;lt;- predict(predicted_age, full4[is.na(full4$Age), 
    ])

# Check the summary to make sure there are no more NA values
summary(full4$Age)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.17   22.00   28.50   29.72   37.00   80.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s take a quick look at the age distribution of passengers with originally known ages, and the age distribution of the entire group (known and predicted ages) to make sure we didn&amp;rsquo;t terribly skew the distribution.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-32-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-32-2.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hmm, seems to have shifted a bit, but that could be due to a greater lack of age information collected for middle-aged passengers.&lt;/p&gt;

&lt;h2 id=&#34;modeling-for-survival&#34;&gt;Modeling for Survival&lt;/h2&gt;

&lt;p&gt;First things first, I need to split out the test and training data back into separate data sets, now called &lt;code&gt;train_complete&lt;/code&gt; and &lt;code&gt;test_complete&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train_complete &amp;lt;- full4[full4$Dataset == &amp;quot;train&amp;quot;, ]
test_complete &amp;lt;- full4[full4$Dataset == &amp;quot;test&amp;quot;, ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because I plan on using the &lt;code&gt;caret&lt;/code&gt; package for all of my modeling, I&amp;rsquo;m going to generate a standard &lt;code&gt;trainControl&lt;/code&gt; so that those tuning parameters remain consistent throughout the various models.&lt;/p&gt;

&lt;h3 id=&#34;creating-traincontrol&#34;&gt;Creating trainControl&lt;/h3&gt;

&lt;p&gt;I will create a system that will perform 10 repeats of a 10-Fold cross-validation of the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;myControl &amp;lt;- trainControl(method = &amp;quot;cv&amp;quot;, number = 10, repeats = 10, 
    verboseIter = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;fitting-a-random-forest-model&#34;&gt;Fitting a random forest model&lt;/h3&gt;

&lt;p&gt;The first type of model I&amp;rsquo;d like to use is a random forest model (using the &lt;code&gt;ranger&lt;/code&gt; and &lt;code&gt;caret&lt;/code&gt; packages).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rf_model &amp;lt;- train(Survived ~ Age + Pclass + Sex + SibSp + Parch + 
    Fare + Embarked + Titles + FamilySize + TravelGroup + GroupSize, 
    tuneGrid = data.frame(mtry = c(2, 5, 8, 10, 15)), data = train_complete, 
    method = &amp;quot;ranger&amp;quot;, trControl = myControl, importance = &amp;quot;impurity&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;fitting-a-glmnet-model&#34;&gt;Fitting a glmnet model&lt;/h3&gt;

&lt;p&gt;Next, we&amp;rsquo;ll try a glmnet model, also from the &lt;code&gt;caret&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;glm_model &amp;lt;- train(Survived ~ Age + Pclass + Sex + SibSp + Parch + 
    Fare + Embarked + Titles + FamilySize + TravelGroup + GroupSize, 
    method = &amp;quot;glmnet&amp;quot;, tuneGrid = expand.grid(alpha = 0:1, lambda = seq(1e-04, 
        1, length = 20)), data = train_complete, trControl = myControl)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;comparing-model-fit&#34;&gt;Comparing model fit&lt;/h3&gt;

&lt;p&gt;Now that we have a random forest model and a glmnet model, it&amp;rsquo;s time to compare their fit.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a list of models
models &amp;lt;- list(rf = rf_model, glmnet = glm_model)

# Resample the models
resampled &amp;lt;- resamples(models)

# Generate a summary
summary(resampled)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 
## Call:
## summary.resamples(object = resampled)
## 
## Models: rf, glmnet 
## Number of resamples: 10 
## 
## Accuracy 
##          Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## rf     0.7667  0.7893 0.8146 0.8250  0.8669 0.8889    0
## glmnet 0.7889  0.8118 0.8531 0.8418  0.8624 0.9101    0
## 
## Kappa 
##          Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## rf     0.5215  0.5375 0.6083 0.6239  0.7092 0.7613    0
## glmnet 0.5535  0.6026 0.6842 0.6617  0.7027 0.8117    0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Plot the differences between model fits
dotplot(resampled, metric = &amp;quot;Accuracy&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-37-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like the glmnet model is slightly more accurate than the random forest model, so we&amp;rsquo;ll use that to predict the survival rate.&lt;/p&gt;

&lt;p&gt;Ok, time to make some predictions.&lt;/p&gt;

&lt;h2 id=&#34;predicting-survival&#34;&gt;Predicting Survival&lt;/h2&gt;

&lt;p&gt;Although I generated two models above, the glmnet model provided higher accuracy, so I&amp;rsquo;ll use that model to predict survival in the test set.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Reorder the data by Passenger ID number
test_complete &amp;lt;- test_complete %&amp;gt;% arrange(PassengerId)

# Make predicted survival values
my_prediction &amp;lt;- predict(glm_model, test_complete)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;preparing-the-prediction-for-kaggle&#34;&gt;Preparing the prediction for Kaggle&lt;/h3&gt;

&lt;p&gt;The instructions on Kaggle indicate that they are expecting a csv file with 2 columns: Passenger ID and Survived. I need to make sure that my data are arranged properly.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a data frame with two columns: PassengerId &amp;amp;
# Survived where Survived contains my predictions.
my_solution_5 &amp;lt;- data.frame(PassengerID = test$PassengerId, Survived = my_prediction)

# Write the solution to a csv file
write.csv(my_solution_5, file = &amp;quot;my_solution_5.csv&amp;quot;, row.names = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;testing-with-kaggle&#34;&gt;Testing with Kaggle&lt;/h3&gt;

&lt;p&gt;Looks like that submission scored 0.80383! Not bad!!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I&amp;rsquo;d love to hear any feedback you may have on this process. Thanks in advance!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>/projects/moviedialogueinteractive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects/moviedialogueinteractive/</guid>
      <description>&lt;!doctype html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;!--The browser can use non-English-language characters (...kind of) --&gt;
		&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1&#34;&gt;
		&lt;link href=&#34;style.css&#34; rel=&#34;stylesheet&#34;&gt;
		&lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css&#34;&gt;
		&lt;link href=&#34;https://fonts.googleapis.com/css?family=Quattrocento:700|Quattrocento+Sans&#34; rel=&#34;stylesheet&#34;&gt;
		&lt;meta charset=&#34;utf-8&#34;&gt;
		&lt;style&gt;
		* 
	
		svg {
			background: #f1f1f1;
		}
		&lt;/style&gt;

		&lt;meta name=&#34;description&#34; content=&#34;Gender Equality and Dialogue in 2016’s Highest Grossing Films&#34; /&gt;
&lt;meta name=&#34;keywords&#34; content=&#34;datascience, gender, gender equality, Hollywood, movies, 2016, Captain America:Civil War, Finding Dory, Zootopia, The Jungle Book, Rogue One, Batman V. Superman, Suicide Squd, Secret Life of Pets, Fantastic Beasts and Where to Find Them, Deadpool, R, datascience, d3js, javascript, interactive, data visualization, Amber Thomas, Amber R Thomas&#34; /&gt;
&lt;meta name=&#34;author&#34; content=&#34;Amber Thomas&#34; /&gt;
&lt;meta name=&#34;robots&#34; content=&#34;all&#34; /&gt;
&lt;meta name=&#34;copyright&#34; content=&#34;Copyright ©2017 - www.proquestionasker.github.io - All Rights Reserved.&#34; /&gt;


	&lt;/head&gt;
	&lt;body&gt;
		&lt;div id=&#34;wrapper&#34;&gt;

		&lt;div id=&#34;sidebar&#34;&gt;
			&lt;h1&gt;Gender Equality and Dialogue in 2016’s Highest Grossing Films&lt;/h1&gt;
			&lt;p&gt;In 2016, several new movie releases featured a lead female character. Does that indicate males and females now share equal roles and dialogue in films? To answer that question, I counted the number of words spoken by each character in 2016&#39;s Highest Grossing Films. &lt;/p&gt;
			&lt;p&gt;Every circle represents a single speaking character. The size of each circle is scaled based on the number of words spoken by that character.&lt;/p&gt;
			&lt;img id=&#34;legend&#34; src=&#34;SidebarLegend.png&#34; height=&#34;212&#34; width=&#34;181&#34; /&gt;
			
		&lt;/div&gt;	

		&lt;div id=&#34;content&#34;&gt;
			&lt;div id=&#34;chart&#34;&gt;&lt;/div&gt;
			&lt;div id=&#34;credit&#34;&gt;
			&lt;p class=&#34;credit-bold&#34;&gt;Created by &lt;a href=&#34;https://twitter.com/ProQuesAsker&#34; target=&#34;_new&#34;&gt;Amber Thomas&lt;/a&gt; &lt;/p&gt;
			&lt;p class=&#34;credit-note&#34;&gt;Worldwide Movie Gross from &lt;a href=&#34;http://www.the-numbers.com/movie/records/worldwide/2016&#34; target=&#34;_new&#34;&gt;The Numbers&lt;/a&gt;.&lt;/p&gt; 
			&lt;p class=&#34;credit-note&#34;&gt;Word counts from movie transcripts. Process described &lt;a href=&#34;https://proquestionasker.github.io/projects/MovieDialogue/&#34; target=&#34;_new&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
			



		&lt;/div&gt;

		&lt;!-- This is D3 our graphing library --&gt;
		&lt;script src=&#34;https://d3js.org/d3.v4.js&#34;&gt;&lt;/script&gt;
	

		&lt;!--Now we include our actual visualization --&gt;

		&lt;script src=&#34;movie_bubbles3.js&#34;&gt;&lt;/script&gt;
	&lt;/div&gt;
	&lt;/body&gt;
&lt;/html&gt;	</description>
    </item>
    
  </channel>
</rss>